# 1 从贝叶斯统计到变分推断

$$
\begin{aligned}
\mathrm{p}(\theta \mid \mathrm{x}) &=\frac{\mathrm{p}(\theta, \mathrm{x})}{\mathrm{p}(\mathrm{x})}=\frac{\mathrm{p}(\mathrm{x} \mid \theta) \mathrm{p}(\theta)}{\mathrm{p}(\mathrm{x})} \\
\mathrm{Posterior} &=\frac{\text { Likelihood } \times \text { Prior }}{\text { Evidence }}
\end{aligned}
$$

上式把原来的表示数据样本的 D换成了x ，这里x 表示任何观测到的量，而不再局限于数据集样本。同样 θ  也有更广泛的意义，表示所有我们感兴趣的未知量，也称隐变量（latent random variables），它可以包括模型的参数，模型中间的未知结果等等。

而推断要完成的就是在给定观测变量下，求解隐变量的后验分布，即求 p ( θ ∣ x ) 

## 1.1 近似推断

在一些情况下我们需要得到后验分布，但是在求解后验分布的时候，根据公式，分母部分（也称作Evidence） $p(x)=\int_{\theta} \mathrm{p}\left(\mathrm{x} , \theta\right) \mathrm{d} \theta$这个积分通常没有封闭解（closed form）或者有指数的计算复杂度。在这种情况下，要进行精确推断不可行或者太复杂，可以使用近似推断。

近似推断有两种比较常用的方法，第一种马尔科夫蒙特卡洛方法（Markov Chain Monte Carlo，MCMC）这种方法的理论依据依然是大数定律，通过大量的采样来进行逼近。另一种就是变分推断（Variational Inference）

# 2 变分推断

变分推断的思想是利用近似推断，找到一个高仿的分布q(θ) 来替代。

这个问题可以分解为两个问题：
（1）近似分布q(θ) 要从哪去选
（2）如何去衡量两个分布的相似性

## 2.1如何衡量两个分布的相似性

KL散度可以衡量两个分布的相似性。于是假设已经有一个q(θ) 的候选分布集合Q，通过计算q(θ) 和 p(θ∣x) 之间的KL散度，找到 Q 中最相似的分布，于是变成了一个优化问题。
$$
\begin{aligned}
\mathrm{q}^{*}(\theta) &=\underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}} \mathrm{D}_{\mathrm{KL}}[\mathrm{q}(\theta) \| \mathrm{p}(\theta \mid \mathrm{x})] \\
=& \underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}}\left\{\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta \mid \mathrm{x}))]\right\} \\
=& \underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}}\left\{\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]+\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\mathrm{x}))]\right\} \\
=& \underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}}\left\{\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]+\log (\mathrm{p}(\mathrm{x}))\right\} \\
=& \underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}}\left\{\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]\right\}
\end{aligned}
$$
在求$\underset{\mathrm{q}(\theta) \in \mathrm{Q}}{\operatorname{argmin}}$的情况下，可以把log(p(x)) 视作是一个常数而省略。

根据KL散度的性质，$\mathrm{D}_{\mathrm{KL}}[\mathrm{q}(\theta) \| \mathrm{p}(\theta \mid \mathrm{x})]≥0$，于是可得
$$
\begin{array}{c}
\mathrm{D}_{\mathrm{KL}}[\mathrm{q}(\theta) \| \mathrm{p}(\theta \mid \mathrm{x})]=\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]+\log (\mathrm{p}(\mathrm{x})) \geq 0 \\
\log (\mathrm{p}(\mathrm{x})) \geq \mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]
\end{array}
$$
由于p(x) 被称作Evidence，而$\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{p}(\theta, \mathrm{x}))]-\mathrm{E}_{\theta \sim \mathrm{q}(\theta)}[\log (\mathrm{q}(\theta))]$是Evidence的下界，故而也称其为Evidence Lower Bound（ELBO），也就是变分下界。于是优化目标就是最小化−ELBO(q) ，或者最大化ELBO(q) 。

## 2.2 q(θ) 要从哪去选

要缩小优化的范围，就需要对q(θ) 加入假设条件。这里有两种假设条件来缩小范围。

1. **Mean Field Approximation**

这种方法假设$ \theta = \lbrace \theta_1, \theta_2,..., \theta_m \rbrace$ ，其中 $ \theta_1, \theta_2,..., \theta_m$之间相互独立。则
$$
\mathrm{q}(\theta)=\prod_{\mathrm{i}=1}^{\mathrm{m}} \mathrm{q}_{\mathrm{j}}\left(\theta_{\mathrm{j}}\right)
$$

2. **Parametric Approximation**

这种方法假设 θ 由另一组参数 λ决定
$$
\mathrm{q}(\theta)=q(\theta|\lambda)
$$
