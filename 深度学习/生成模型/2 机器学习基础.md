设数据集为$ D=\{x_1,x_2,...,x_n\}$，数据集中的数据都是独立同分布的。假设这些数据是以含有未知参数 θ 某种概率形式分布的，任务是通过已有的数据来估计这个未知的参数 θ 。

代入到机器学习中，数据集是$p_{data}$中采样得到的，而我们需要训练模型使得模型得到的分布$p_{model}$与原始数据分布尽可能的一致，而 $p_{model}$依赖于参数 θ。

于是目标就是在给定数据集D的情况下，去找到参数 θ 。而且频率学派的最大似然估计，和贝叶斯学派的最大后验概率的区别也是围绕着如何去找参数 θ 展开的。用公式表示，目标便是求 $p(\theta|D)$
$$
\mathrm{p}(\theta \mid \mathrm{D})=\frac{\mathrm{p}(\theta, \mathrm{D})}{\mathrm{p}(\mathrm{D})}=\frac{\mathrm{p}(\mathrm{D} \mid \theta) \mathrm{p}(\theta)}{\mathrm{p}(\mathrm{D})}
$$


# 1最大似然估计

## 1.1 最大似然估计

频率学派认为存在唯一的真实常数参数。也就是说最优的参数 θ 是确定的只有一个。但是由于一些外界噪声的干扰，采样得到的数据看起来并不完全是由参数决定的。不过虽然由误差存在，只要在这个给定的数据的情况下，找到一个概率最大的参数就可以了。

最大似然估计的思想是最大化给定数据的时候找到的$\theta$ 的可能性。最大似然估计的目标：
$$
\underset{\theta}{\operatorname{argmax}}p(\theta \mid \mathrm{D})=\underset{\theta}{\operatorname{argmax}} \frac{\mathrm{p}_{\text {model }}(\mathrm{D} \mid \theta) \mathrm{p}(\theta)}{\mathrm{p}(\mathrm{D})}
$$


在最大似然估计中假设的前提是参数θ是一个确定的值，p (θ) 就是一个常数，而p(D) 是已有的数据集的分布，也是确定的,可以视作常数。再加上数据集中的数据都是独立同分布的前提条件，于是目标就变成了如下的似然函数：
$$
\underset{\theta}{\operatorname{argmax}} \operatorname{p}_{\text {model }}(\mathrm{D} \mid \theta)=\underset{\theta}{\operatorname{argmax}} \prod_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)
$$
在 argmax的条件下，取log不改变结果，因此可以进一步的转换成对数似然函数
$$
\underset{\theta}{\operatorname{argmax}} \operatorname{p}_{\operatorname{model}}(\mathrm{D} \mid \theta)=\underset{\theta}{\operatorname{argmax}} \prod_{\mathrm{i}=1}^{\mathrm{n}} \operatorname{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)=\underset{\theta}{\operatorname{argmax}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right)
$$

## 1.2 最大似然估计与交叉熵和KL散度

在  argmax条件下，缩放代价函数不改变结果
$$
\begin{aligned}
\underset{\theta}{\operatorname{argmax}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right) &=\frac{1}{\mathrm{n}} \underset{\theta}{\operatorname{argmax}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right) \\
&=-\frac{1}{\mathrm{n}} \underset{\theta}{\operatorname{argmin}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right)
\end{aligned}
$$
根据辛钦大数定律，当 $n\rightarrow \infin$ 时
$$
\lim _{\mathrm{n} \rightarrow \infty}\left(\left|\frac{1}{\mathrm{n}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}(\mathrm{x} \mid \theta)\right)-\mathrm{E}\left(\log \left(\mathrm{p}_{\operatorname{model}}(\mathrm{x} \mid \theta)\right)\right)\right|<\epsilon\right)=1
$$
即在数据量很大时有
$$
\lim _{\mathrm{n} \rightarrow \infty}\left(\frac{1}{\mathrm{n}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\operatorname{model}}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right)\right)=\mathrm{E}\left(\log \left(\mathrm{p}_{\operatorname{model}}(\mathrm{x} \mid \theta)\right)\right)
$$
数据集中的$x_i $都是从数据的分布$p_{data}$中采样得到的，本身就服从一个分布，因而
$$
\begin{aligned}
\mathrm{E}\left(\log \left(\mathrm{p}_{\text {model }}(\mathrm{x} \mid \theta)\right)\right) &=\mathrm{E}_{\mathrm{x} \sim \mathrm{p}_{\text {data }}}\left(\log \left(\mathrm{p}_{\text {model }}(\mathrm{x} \mid \theta)\right)\right) \\
-\frac{1}{\mathrm{n}} \underset{\theta}{\operatorname{argmin}} \sum_{\mathrm{i}=1}^{\mathrm{n}} \log \left(\mathrm{p}_{\text {model }}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right) &=\underset{\theta}{\operatorname{argmin}} \mathrm{E}_{\mathrm{x} \sim \mathrm{p}_{\text {data }}}\left(\log \left(\mathrm{p}_{\text {model }}(\mathrm{x} \mid \theta)\right)\right)
\end{aligned}
$$
显然可以看出最大似然估计的目标就是最小化$p_{data}$和 $p_{model}$的交叉熵。而交叉熵加上一个常数项就是$p_{data}$和$p_{model}$的KL散度。
$$
\mathrm{D}_{\mathrm{KL}}\left(\mathrm{p}_{\text {data }}(\mathrm{x}) \| \mathrm{p}_{\text {model }}(\mathrm{x} \mid \theta)\right)=\sum_{\mathrm{x}} \mathrm{p}_{\text {data }}(\mathrm{x}) \log \left(\mathrm{p}_{\text {data }}(\mathrm{x})\right)-\sum_{\mathrm{x}} \mathrm{p}_{\text {data }}(\mathrm{x}) \log \left(\mathrm{p}_{\text {model }}(\mathrm{x} \mid \theta)\right)
$$

# 2 贝叶斯统计与最大后验概率

## 2.1贝叶斯统计

在掌握数据集D之前，参数 θ 的分布p(θ) 称为**先验分布**。而在掌握了数据集之后，参数的分布p(θ∣D) 就称为**后验分布**。先后即是指是否掌握了条件信息。

贝叶斯学派认为参数本身存在一个概率分布，并没有唯一真实参数，参数空间里的每个值都可能是真实模型使用的参数，区别只是概率不同。频率学派的看法就是参数是由数据样本估计得来的，没有数据样本就无从谈起参数。但是这并不是贝叶斯学派的考虑，贝叶斯估计中参数的先验分布很重要。而先验在很多时候完全是假设，然后去验证已有的数据是否吻合先验猜想。总之，**先验是与数据样本无关的。**

频率派适用在数据样本数量很大的时候，而贝叶斯派在数据样本较少的时候的表现会比频率派要好。在数据样本数量很大的时候，两者都会有准确的结果，但是相比之下贝叶斯派的计算成本要高得多。

$\mathrm{p}(\theta \mid \mathrm{D})=\frac{\mathrm{p}(\theta, \mathrm{D})}{\mathrm{p}(\mathrm{D})}=\frac{\mathrm{p}(\mathrm{D} \mid \theta) \mathrm{p}(\theta)}{\mathrm{p}(\mathrm{D})}$式中除了分母可以看作一个归一化因子外，其余都是概率分布的函数，也就是说 p ( θ ) p(\theta)p(θ) 不能再被看做常数，那么就需要对上式进行变形
$$
\begin{array}{l}
\mathrm{p}(\mathrm{D}) = \int_{\theta} \mathrm{p}(\mathrm{D} \mid \theta) \mathrm{p}(\theta) \mathrm{d} \theta \\
\mathrm{p}(\mathrm{D} \mid \theta) = \prod_{\mathrm{i} = 1}^{\mathrm{n}} \mathrm{p}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right) \\
\mathrm{p}(\theta \mid \mathrm{D}) = \frac{\left(\prod_{\mathrm{i} = 1}^{\mathrm{n}} \mathrm{p}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right)\right) \mathrm{p}(\theta)}{\int_{\theta} \prod_{\mathrm{i} = 1}^{\mathrm{n}} \mathrm{p}\left(\mathrm{x}_{\mathrm{i}} \mid \theta\right) \mathrm{p}(\theta) \mathrm{d} \theta}
\end{array}
$$
**通过贝叶斯统计，我们得到的不是单一的θ，而是一个分布p(θ∣D) 。** 之后的处理方式有两种。第一种是用期望E(p(θ∣D)) 来估计 θ。这种方式相对简单，因为可以少算一次积分。但是结果会不太准确。第二种方式是保留E(p(θ∣D)) ，而在预测的时候，用求边缘分布的方式，即 $\int_{\theta} \mathrm{p}\left(\mathrm{x}^{\prime} \mid \theta\right) \mathrm{p}(\theta \mid \mathrm{D}) \mathrm{d} \theta$，这种方式需要求积分，相对复杂，但是结果会相对更准确。

可以看出，直接用贝叶斯统计的方法需要求积分，而且这种积分通常没有解析解，就需要用近似推断（Approximate Inference）来估计，比如马尔科夫蒙特卡洛方法（MCMC），又或者变分推断（Variational Inference）。那么一个很重要的问题，如何在保证准确率不受太大影响的前提下去降低贝叶斯方法的计算复杂度。一种可行的方法就是最大后验概率（MAP）。

## 2.2最大后验概率（MAP）

为了避免求积分的运算，一种可行的思路就是在贝叶斯估计中，采用极大似然估计的思想，考虑后验分布极大化而求解参数 θ，这样就变成了最大后验估计（Maximum A Posterior estimation，MAP）
$$
\underset{\theta}{\operatorname{argmax}}p(\theta \mid \mathrm{D})=\underset{\theta}{\operatorname{argmax}} \frac{\mathrm{p}(\mathrm{D} \mid \theta) \mathrm{p}(\theta)}{\mathrm{p}(\mathrm{D})}
$$
与之前极大似然估计相同的地方是这里的分母p(D) 依然可以看作是常数，但是不同的地方是p(θ) 不能被看作是个常数了，于是优化的目标就可以写作
$$
\underset{\theta}{\operatorname{argmax}}p(\mathrm{D} \mid \theta) \mathrm{p}(\theta)=\underset{\theta}{\operatorname{argmax}}(\log (\mathrm{p}(\mathrm{D} \mid \theta)+\log (\mathrm{p}(\theta)))
$$
**可以看出目标的前半部分log(p(D∣θ)与最大似然估计的似然函数是一样的，不同在于后半部分的log(p(θ)) ，本质其实是正则化项**。例如假设参数$\theta$的先验服从均值为0的正态分布，则对正态分布取对数之后，得到的就是L2正则化项乘一个缩放因子。

# KL散度 & 交叉熵

## 交叉熵

假设两个概率分布p(X)，q(X) ，交叉熵为：
$$
\begin{aligned}
\mathrm{H}(\mathrm{p}, \mathrm{q}) &=-\sum_{\mathrm{x}} \mathrm{p}(\mathrm{x}) \log (\mathrm{q}(\mathrm{x})) \\
&=-\mathrm{E}_{\mathrm{x} \sim \mathrm{p}(\mathrm{x})}(\log (\mathrm{q}(\mathrm{x})))
\end{aligned}
$$

## KL散度

KL散度也称作相对熵，用来衡量两个分布之间的相似程度
$$
\begin{align}
\mathrm{D}_{\mathrm{KL}}(\mathrm{p} \| \mathrm{q}) & = \sum_{\mathrm{x}} \mathrm{p}(\mathrm{x}) \log \left(\frac{\mathrm{p}(\mathrm{x})}{\mathrm{q}(\mathrm{x})}\right) \\ & = \sum_{\mathrm{x}} \mathrm{p}(\mathrm{x}) \log (\mathrm{p}(\mathrm{x}))-\sum_{\mathrm{x}} \mathrm{p}(\mathrm{x}) \log (\mathrm{q}(\mathrm{x})) \\
\mathrm{D}_{\mathrm{KL}}(\mathrm{q} \| \mathrm{p}) & = \sum_{\mathrm{x}} \mathrm{q}(\mathrm{x}) \log \left(\frac{\mathrm{q}(\mathrm{x})}{\mathrm{p}(\mathrm{x})}\right) \\ & = \sum_{\mathrm{x}} \mathrm{q}(\mathrm{x}) \log (\mathrm{q}(\mathrm{x}))-\sum_{\mathrm{x}} \mathrm{q}(\mathrm{x}) \log (\mathrm{p}(\mathrm{x}))
\end{align}
$$
KL散度的性质：
$$
\begin{array}{l}
\text { (1) } \mathrm{D}_{\mathrm{KL}}(\mathrm{p} \| \mathrm{q}) \neq \mathrm{D}_{\mathrm{KL}}(\mathrm{q} \| \mathrm{p}) \\
\text { (2) } \mathrm{D}_{\mathrm{KL}}(\mathrm{p} \| \mathrm{q}) = 0 \Leftrightarrow \mathrm{p} = \mathrm{q} \\
\text { (3) } \mathrm{D}_{\mathrm{KL}}(\mathrm{p} \| \mathrm{q}) \geq 0
\end{array}
$$
