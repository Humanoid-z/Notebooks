[TOC]



# 一、卷积神经网络

## 1.1 卷积神经网络基础

### 1.1.1 计算机视觉介绍

计算机视觉面临的一个问题是数据的输入可能会非常大，对于一张1000×1000的图片，特征向量的维度达到了1000×1000×3，因为有3个**RGB**通道，最终特征数量达到300万。

300万的输入特征，在第一隐藏层中，假设有1000个隐藏单元，则在全连接网络中矩阵 $W^{[1]}$大小将会是1000×300万，即有30亿个参数。在参数如此大量的情况下，难以获得足够的数据来防止神经网络发生过拟合和竞争需求，同时要处理包含30亿参数的神经网络，所需的巨大内存让人不能接受。为此需要进行卷积计算

### 1.1.2 边缘检测示例

卷积运算是卷积神经网络最基本的组成部分

让电脑去搞清楚照片里有什么物体时，可能第一件事是进行边缘检测，如检测图片中的垂直边缘。

此时可以构造一个3×3矩阵，或者称过滤器$\begin{bmatrix}1 & 0 & -1\\ 1 & 0 & -1\\ 1 & 0 & -1\end{bmatrix}$。

对这个6×6的图像用3×3的过滤器对其进行卷积

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214142315.png" style="zoom: 67%;" />

卷积运算是过滤器和矩阵对应位置元素相乘的累加和，通过不断移动卷积区域来获得右边4*4的矩阵。

深度学习中卷积的定义实际上是数学的互相关运算，但通常把它叫做卷积运算。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211210223625.png" alt="img" style="zoom:67%;" />

对于这个6×6灰度图像，左边像素值10是比较亮的部分，右边像素值比较暗，显灰色。在图片中间有一个特别明显的垂直边缘。

当用这个过滤器进行卷积运算的时候，这个过滤器可视为：左边有明亮的像素，然后是一个过渡0，然后右边是深色的。卷积运算后，得到的是右边的矩阵。输出图像中间的亮处，表示在图像中间有一个特别明显的垂直边缘。

由于这个例子中图片太小，检测到的边缘相对太粗了，如果用一个1000×1000的图像能够更好地检测出图像中的垂直边缘。

可以通过改变卷积核来检测水平边缘

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214142636.png" style="zoom:67%;" />

在神经网络中，通常将过滤器的所有数字都设置为参数，通过反向传播算法自动去学习它们。

### 1.1.3 Padding

**padding**是一个基本的卷积操作

在上一节中，如果用一个3×3的过滤器卷积一个6×6的图像，最后会得到一个4×4的输出。因为3×3过滤器在6×6矩阵中，只可能有4×4种可能的位置。公式为：$n×n$的图像，用$f×f$的过滤器做卷积，输出维度是$(n-f+1)×(n-f+1)$。

这样的话会有两个缺点，第一个缺点是每次做卷积操作，图像就会缩小。可能做了几次之后，图像就会变得很小，甚至缩小到只有1×1的大小，不利于构造深层的卷积网络。

第二个缺点是，角落边缘的像素只被一个输出所使用。但如果是在中间的像素点，就会有许多3×3的卷积区域与之重叠。所以那些在角落或者边缘区域的像素点在输出中采用较少，意味着丢掉了图像边缘位置的许多信息。

为了解决这些问题，可以在卷积操作之前填充这幅图像。在这个案例中，可以沿着图像边缘再填充一层像素。将6×6的图像填充成8×8的图像。如果用3×3的图像对这个8×8的图像卷积，得到的输出就是6×6的图像。习惯上用0去填充。如果$p$是在图像周围填充像素的圈数，输出也就变成了$(n+2p-f+1)×(n+2p-f+1)$。

根据选择填充多少像素，分为**Valid**卷积和**Same**卷积。

**Valid**卷积意味着不填充，这样的话，如果有一个$n×n$的图像，用一个$f×f$的过滤器卷积，会获得一个$(n-f+1)×(n-f+1)$维的输出。

**Same**卷积意味填充后的输出大小和输入大小是一样的。根据公式$n-f+1$，当填充$p$圈的像素点，$n$就变成了$n+2p$，最后公式变为$(n+2p-f+1)×(n+2p-f+1)$。如果想让$n+2p-f+1=n$的话，$p=(f-1)/2$。

在计算机视觉中，$f$通常是奇数。一是因为，如果$f$是一个偶数，那么只能使用不对称填充。只有$f$是奇数的情况下，**Same**卷积才会有自然的填充，可以以同样的数量填充四周。第二个原因是奇数维过滤器有一个中心点，便于指出过滤器的位置。

### 1.1.4 卷积步长（Strided convolutions）

卷积中的步幅是另一个构建卷积神经网络的基本操作

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214150559.png" style="zoom:67%;" />

用3×3的矩阵卷积一个7×7的矩阵，步长s为2，得到一个3×3的输出。公式如下：$f×f$的过滤器卷积$n×n$的图像，**padding**为$p$，步长为$s$，输出为$\frac{n+2p - f}{s} + 1 \times \frac{n+2p - f}{s} + 1$。当商不是一个整数时向下取整

### 1.1.5 三维卷积（Convolutions over volumes）

对于**RGB**彩色图像，其除了图片的高和宽外还有红绿蓝三个颜色通道，可以把它想象成三个图像的堆叠。过滤器也对应是三维的，图像的通道数必须和过滤器的通道数匹配。

三维卷积和二维卷积类似，将图像和过滤器对应位置的数字相乘相加

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214154833.png" style="zoom:67%;" />

如果使用多个过滤器，则将结果按输出的第三维堆叠，即输出的维度为$(\frac{n+2p - f}{s} + 1 ,\frac{n+2p - f}{s} + 1,n_c)$,$n_c$等于过滤器的数目，也被称为通道数目。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214155339.png" alt="img" style="zoom:67%;" />

### 1.1.6 单层卷积网络

本节介绍如何构建卷积神经网络的卷积层

假设通过两个过滤器卷积处理一个三维图像，输出两个不同的4×4矩阵。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214161420.png" style="zoom:67%;" />

然后对于这2个4×4矩阵增加不同的偏差。再应用非线性激活函数**ReLU**，然后把这两个矩阵堆叠起来，最终得到一个4×4×2的矩阵。这就是卷积神经网络的一层。

总结：对于第l层，输入是$n^{\left\lbrack l - 1 \right\rbrack} \times n^{\left\lbrack l -1 \right\rbrack} \times n_{c}^{\left\lbrack l - 1\right\rbrack}$，输出是$n_{H}^{[l]} \times n_{W}^{[l]} \times n_{c}^{[l]}$，$n_c$是这一层过滤器的数量，$n_{H}^{[l]} = \lfloor\frac{n_{H}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]}}{s^{[l]}} +1\rfloor$，$n_{W}^{[l]} = \lfloor\frac{n_{W}^{\left\lbrack l - 1 \right\rbrack} +2p^{[l]} - f^{[l]}}{s^{[l]}} +1\rfloor$，

过滤器维度等于$f^{[l]} \times f^{[l]} \times n_{c}^{\left\lbrack l - 1 \right\rbrack}$

$f^{[l]}$表示过滤器大小，$p^{[l]}$表示**padding**的数量，$s^{[l]}$表示步长。

### 1.1.7 池化层（Pooling layers）

除了卷积层，卷积网络也经常使用池化层来缩减模型的大小，提高计算速度，同时提高所提取特征的鲁棒性

![](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214163903.png)

通常使用的池化类型是最大池化（**max pooling**）

对于上图的例子就是把4×4的输入拆分成不同的区域，输出的每个元素都是其对应颜色区域中的最大元素值。就像是应用了一个大小为2×2的过滤器，步长为2，这些就是最大池化的超参数。

最大池化运算的直观理解是，可以把输入的4×4矩阵看作是某些特征的集合。数字大意味着可能探测到了某些特定的特征。最大化操作的功能就是只要在任何一个象限内提取到某个特征，它都会保留在最大化的池化输出里。

池化层的一个特点是，它有一组超参数，但并没有参数需要学习。之前计算卷积层输出大小的公式同样适用于最大池化，即$\frac{n + 2p - f}{s} + 1$

另外还有一种类型的池化，平均池化，它不太常用。这种运算是每个过滤器的平均值。

总之，池化层的超参数包括过滤器大小$f$和步长$s$，常用的参数值为$f=2$，$s=2$，其效果相当于高度和宽度缩减一半。

### 1.1.8 卷积神经网络示例

假设有一张大小为32×32×3的输入图片含有某个数字，需要做手写体数字识别，可以构建一个神经网络来实现这个功能。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211214210857.png" style="zoom:67%;" />

输入是32×32×3的矩阵，第一层**CONV1**使用过滤器大小为5×5，步幅是1，**paddin**g是0，过滤器个数为6，那么输出为28×28×6。再增加偏差，应用非线性函数，如**ReLU**，最后输出**CONV1**的结果。

然后构建一个池化层**POOL1**，选择用最大池化，参数$f=2$，$s=2$。28×28变成了14×14，通道数量保持不变，所以最终输出为14×14×6。

在卷积神经网络文献中，卷积有两种分类。一类卷积是一个卷积层和一个池化层一起作为一层，这就是神经网络的**Layer1**。另一类卷积是把卷积层作为一层，而池化层单独作为一层。人们在计算神经网络有多少层时，通常只统计具有权重和参数的层。因为池化层没有权重和参数，只有一些超参数。这里把**CONV1**和**POOL1**共同作为一个卷积，并标记为**Layer1**。

再构建一个卷积层**CONV2**，过滤器大小为5×5，步幅为1，使用16个过滤器，最后输出一个10×10×16的矩阵。

再构建一个最大池化**POOL2**，超参数$f=2$，$s=2$，最后输出为5×5×16。

5×5×16矩阵包含400个元素，将**POOL2**平整为一个大小为400的一维向量。下一层含有120个单元，这就是第一个全连接层，标记为**FC3**。它的权重矩阵为$W^{\left\lbrack 3 \right\rbrack}$，维度为120×400。

然后对这个120个单元再添加一个全连接层，含有84个单元，标记为**FC4**。

最后，用这84个单元填充一个**softmax**单元。如果想通过手写数字识别来识别手写0-9这10个数字，这个**softmax**就会有10个输出。

随着神经网络深度的加深，高度$n_{H}$和宽度$n_{W}$通常都会减少，而通道数量会增加，然后得到一个全连接层。

在神经网络中，另一种常见模式就是一个或多个卷积后面跟随一个池化层，再然后是一个或多个卷积层后面再跟一个池化层，然后是几个全连接层，最后是一个**softmax**。这是神经网络的另一种常见模式。

### 1.1.9 为什么使用卷积？（Why convolutions?）

卷积层的两个主要优势在于参数共享和稀疏连接。

观察发现，特征检测如垂直边缘检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。也就是说，如果用一个3×3的过滤器检测垂直边缘，那么图片的各个区域都可以使用这个3×3的过滤器。即过滤器可以在输入图片的不同区域中使用同样的参数，以便提取垂直边缘或其它特征。它不仅适用于边缘特征这样的低阶特征，同样适用于高阶特征，例如提取脸上的眼睛，猫或者其他特征对象。

第二个是稀疏连接。对于6×6的输入特征，每一个输出值仅与36个输入特征中9个相关(如果使用3×3的过滤器)。而且其它像素值都不会对输出产生任影响，这就是稀疏连接的概念。

神经网络可以通过这两种机制减少参数，以便用更小的训练集来训练它，从而预防过度拟合。

## 1.2 深度卷积网络

### 1.2.1 经典网络

本节介绍几个经典的神经网络结构，分别是**LeNet-5**、**AlexNet**和**VGGNet**

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215135145.png" style="zoom:67%;" />

**LeNet-5**：**LeNet-5**是针对灰度图片训练的，所以假设输入图片是32×32×1。**LeNet-5**使用6个5×5的过滤器，步长为1，**padding**为0，输出结果为28×28×6。然后进行池化操作，使用平均池化，过滤器的宽度为2，步长为2，图像的尺寸，高度和宽度都缩小了2倍，输出结果是14×14×6的图像。接下来是第二个卷积层，使用一组16个5×5的过滤器，新的输出10×10×16。然后又是池化层，高度和宽度再缩小一半，输出一个5×5×16的图像。下一层是全连接层，有120个神经元，第二个全连接层有84个神经元。最后一步就是利用这84个特征得到最后的输出，可以在这里再加一个节点用来预测$\hat{y}$的值，$\hat{y}$有10个可能的值，对应识别0-9这10个数字。在现在的版本中则使用**softmax**函数输出十种分类结果。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215135913.png" style="zoom:67%;" />

**AlexNet**：用一张227×227×3的图片作为输入，第一层使用96个11×11的过滤器，步幅为4，因此尺寸缩小到55×55。然后用一个3×3的过滤器构建最大池化层，$f=3$，步幅$s$为2，卷积层尺寸缩小为27×27×96。接着再执行一个5×5的**same**卷积，**padding**之后，输出是27×27×276。然后再次进行最大池化，尺寸缩小到13×13。再执行三次**same**卷积，最后再进行一次最大池化，尺寸缩小到6×6×256。将其展开为9216个单元，然后是一些全连接层。最后使用**softmax**函数输出识别的结果。**LeNet-5**大约有6万个参数，而**AlexNet**包含约6000万个参数。**AlexNet**比**LeNet**表现更为出色的另一个原因是它使用了**ReLu**激活函数。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215141452.png" style="zoom:67%;" />

**VGG-16**：最开始是两层**same**卷积，64个3×3的过滤器，步幅为1，输出结果是224×224×64，然后是一个最大池化层，用一个2×2，步幅为2的过滤器构建，输出112×112×64。然后又是2个**same**卷积层，使用128个过滤器，输出112×112×128，然后是一个最大池化层，输出56×56×128。如此进行几轮操作后，将最后得到的7×7×512的特征图进行全连接操作，得到4096个单元，然后进行**softmax**激活，输出从1000个对象中识别的结果。

VGG16相比AlexNet的一个改进是**采用连续的几个3x3的卷积核代替AlexNet中的较大卷积核（11x11，7x7，5x5）**。对于给定的感受野（与输出有关的输入图片的局部大小），采用堆积的小卷积核是优于采用大的卷积核，因为多层非线性层可以增加网络深度来保证学习更复杂的模式，而且代价还比较小（参数更少）。

简单来说，在VGG中，使用了3个3x3卷积核来代替7x7卷积核，使用了2个3x3卷积核来代替5*5卷积核，这样做的主要目的是在保证具有相同感知野的条件下，提升了网络的深度，在一定程度上提升了神经网络的效果。

### 1.2.2 残差网络(ResNets)

**ResNets**是由残差块（**Residual block**）构建的。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215211052.png" style="zoom:67%;" />

典型的残差块包含一个两层神经网络和一条跳跃链接。跳跃链接是将$a^{[l]}$直接向后拷贝到第二层的线性计算之后，在**ReLU激活函数前**加上$a^{[l]}$，即$\ a^{\left\lbrack l + 2 \right\rbrack} = g\left(z^{\left\lbrack l + 2 \right\rbrack} + a^{[l]}\right)$

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215211614.png" style="zoom:50%;" />

上图是很多残差块堆叠形成的一个残差神经网络

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211215211702.png" style="zoom:50%;" />

如果使用标准优化算法训练一个普通网络，经验上会发现随着网络深度的加深，训练错误会先减少，然后增多。而理论上，随着网络深度的加深，应该训练得越来越好才对。也就是说，对于一个普通网络来说，深度越深意味着用优化算法越难训练，随着网络深度的加深，训练错误会越来越多。

而对于**ResNets**，即使网络再深，训练误差也能够逐渐减少

残差网络作用的理解：假设有一个大型神经网络，整个网络中使用**ReLU**激活函数，其输入为$X$，输出激活值$a^{[l]}$。再给这个网络额外添加一个残差块，最后输出为$a^{\left\lbrack l + 2 \right\rbrack}$。$a^{\left\lbrack l + 2\right\rbrack} = g(z^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$展开为$a^{\left\lbrack l + 2 \right\rbrack} = g(W^{\left\lbrack l + 2 \right\rbrack}a^{\left\lbrack l + 1 \right\rbrack} + b^{\left\lbrack l + 2 \right\rbrack} + a^{\left\lbrack l\right\rbrack})$，如果$W^{\left\lbrack l + 2 \right\rbrack} = 0$，$b^{\left\lbrack l + 2 \right\rbrack} = 0$，则$ a^{\left\lbrack l + 2 \right\rbrack} = \ g\left( a^{[l]} \right) = a^{\left\lbrack l\right\rbrack}$，因为使用**ReLU**激活函数，并且所有激活值都是非负的，所以$a^{[l+2]} =a^{[l]}$。很明显残差块学习这个恒等式函数并不难(即将$W^{\left\lbrack l + 2 \right\rbrack}$和$b^{\left\lbrack l + 2 \right\rbrack}$置零)，如果多添加的两层反而有损模型的准确性，则模型很容易通过梯度下降法将残差块变成一个恒等式

### 1.2.3 网络中的网络以及 1×1 卷积

对于二维平面的卷积，即单通道图片来说，1×1卷积效果不佳，效果只是对输入矩阵乘以某个数字。

1×1卷积对于三维卷积的效果更好

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216151456.png" style="zoom:67%;" />

对于一张6×6×32的图片，使用1×1过滤器进行卷积所实现的功能是遍历这36个单元格，计算左图一个像素中32个通道的32个数字与过滤器中32个数字的乘积之和，然后应用**ReLU**非线性函数。1×1卷积实际上是对每个像素点，在不同的通道上进行线性组合（信息整合），且保留了图片的原有平面结构，调控depth，从而完成升维或降维的功能(取决于过滤器的数量)。也被称为**Network in Network**

1×1卷积的主要作用有以下几点：

1. 降维或升维
2. **加入非线性**。卷积层之后经过激励层，1*1的卷积在前一层的学习表示上添加了非线性激励（ non-linear activation ），提升网络的表达能力；

### 1.2.4 谷歌 Inception 网络

Inception网络的基本思想是**Inception**网络不需要人为决定使用哪个过滤器或者是否需要池化，而是由网络自行确定这些参数，通过给网络添加这些参数的所有可能值，然后把这些输出连接起来，让网络自己学习它需要什么样的参数，采用哪些过滤器组合。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216152601.png" style="zoom:50%;" />

**Inception**模块如上图，是1×1卷积、3×3的过滤器、5×5的过滤器、最大池化层的输出在通道维度上的堆叠，而保持像素的高度宽度维度和输入相同。

但是**Inception**层有一个计算成本的问题，假设对28×28×192的输入块，执行一个5×5卷积，32个过滤器，输出为28×28×32。乘法运算次数=过滤器大小*输出值个数即（5×5×192）\*（28×28×32）约等于1.2亿，而在5×5卷积前使用1×1卷积能够将计算成本降低至一成。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216154626.png" style="zoom:50%;" />

在上图架构中，使用1×1卷积把输入值从192个通道减少到16个通道。然后对这个较小层(又称为瓶颈层)运行5×5卷积，得到最终输出。

前两层的计算成本为：（1×1×192）\*（28×28×16）约等于240万

二三层的计算成本为：（5×5×16）\*（28×28×32）约等于1000万

总和为1204万，与之前比较，计算成本从1.2亿下降到了原来的十分之一

并且只要合理构建瓶颈层，既可以显著缩小表示层规模，又不会降低网络性能，从而节省了计算。

一个构建了瓶颈层的**Inception**模块如下图所示

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216155811.png" style="zoom:67%;" />

然后是**Inception**网络

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216155853.png" style="zoom:67%;" />

### 1.2.5 迁移学习（Transfer Learning）

如果要自己做一个计算机视觉的应用，相比于从头训练权重，可以下载别人已经训练好网络结构的权重，用这个作为预训练，然后转换到自己的任务上。

通过使用其他人预训练的权重，可以在只有很小的训练集的条件下得到很好的性能。并且大多数深度学习框架都允许指定是否训练特定层的权重。可以根据需求训练**softmax**层的权重，并把前面这些层的权重都冻结。可以将训练集中所有样本在冻结层的激活值进行预计算，然后存储到硬盘里，在此之上训练**softmax**分类器以加快训练。

如果有更大的训练集，则应该冻结更少的层

### 1.2.6 数据增强

计算机视觉的主要问题是没有办法得到充足的数据，因此经常用到数据扩充的方法

首先最简单的数据扩充方法就是垂直镜像对称

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216163536.png" style="zoom: 67%;" />

另一个经常使用的技巧是随机裁剪

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216163634.png" style="zoom:50%;" />

第三种经常使用的方法是色彩偏移(Color shifting)

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211216163839.png" style="zoom:50%;" />

颜色失真或者是颜色变换方法，会使得算法对照片的颜色更改更具鲁棒性。

一种影响颜色失真的算法是**PCA**，即主成分分析，**PCA**颜色增强的大概含义是，如果图片呈现紫色，即主要含有红色和蓝色，绿色很少，然后**PCA**颜色增强算法就会对红色和蓝色增减很多，绿色变化相对少一点，使总体的颜色保持一致。

## 1.3 目标检测（Object detection）

### 1.3.1 目标定位（Object localization）

定位分类不仅要用算法识别图片中的物体，还要在图片中标记出它的位置，用边框把物体圈起来。这就需要让神经网络再多输出4个数字，标记为$b_{x}$,$b_{y}$,$b_{h}$和$b_{w}$，这四个数字是被检测对象的边界框的参数化表示。

首先约定符号表示，图片左上角的坐标为$(0,0)$，右下角标记为$(1,1)$。要确定边界框的具体位置，需要指定红色方框的中心点，这个点表示为($b_{x}$,$b_{y}$)，边界框的高度为$b_{h}$，宽度为$b_{w}$。

目标标签$y$的定义如下：$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$

$p_{c}$表示是否含有对象，如果存在要识别的对象（如行人、汽车、摩托车），则$p_{c}= 1$，如果是背景，图片中没有要检测的对象，则$p_{c} =0$。$c_{1}$、$c_{2}$和$c_{3}$，是对象的独热编码，表示对象属于哪一类，如果有三种要识别的对象。

### 1.3.2 目标检测（Object detection）

本节采用的是基于滑动窗口的目标检测算法

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217124736.png" style="zoom:67%;" />

首先需要训练一个目标分类网络，然后对于测试图片，选定一个特定大小的窗口放在图片的左上角，将窗口内的图片输入卷积神经网络，卷积网络开始进行预测，判断红色方框内有没有要识别的目标。接下来红色方框稍向右滑动继续处理第二个图像，依次重复操作，直到这个窗口滑过图像的每一个角落。

滑动窗口目标检测算法有很明显的缺点，大力度或大步幅可能会影响性能。如果采用小粒度或小步幅则意味着超高的计算成本。

### 1.3.3 滑动窗口的卷积实现

滑动窗口的卷积实现，简单地说就是对整张图片进行卷积操作，一次得到所有预测值，原来一个窗口的预测值变成了网络最终输出矩阵的一个像素，如下图，2×2×4的输出一共有4个像素，分别是14×14大小的窗口以2的步长在16×16的图片上滑动的4个结果。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217131333.png" style="zoom:67%;" />

要达到这个效果，首先要把神经网络的全连接层转化成卷积层

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217131812.png" style="zoom:67%;" />

对于上图个全连接层，可以用400个5×5的过滤器实现，输出维度是1×1×400，不再把它看作一个含有400个节点的集合，而是一个1×1×400的输出层。从数学角度看，它和全连接层是一样的，因为这400个值中每个值都有一个5×5×16的过滤器，所以每个值都是上一层5×5×16的激活值经过某个线性函数的输出结果。

再添加另外一个卷积层，使用400个1×1的过滤器，最后经由4个1×1过滤器的处理，得到一个**softmax**激活值，最终得到1×1×4的输出层，而不是4个数字。

用卷积层代替全连接层后，假设输入给卷积网络的图片大小是14×14×3，测试集图片是16×16×3，窗口步幅为2个像素，则窗口在16×16×3的小图像上滑动了4次，可以发现这4次卷积操作中很多计算都是重复的，因此不需要把输入图像分割成四个子集，分别执行前向传播，而是把它们作为一张图片输入给卷积网络进行计算。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217131333.png" style="zoom:67%;" />

### 1.3.4 Bounding Box预测

滑动窗口法的卷积实现，效率更高，但仍然存在问题，不能输出最精准的边界框。使用**YOLO**算法可以得到更精准的边界框。

假设输入图像是100×100，在图像上放一个3×3网格。采用图像分类和定位算法逐一应用在图像的9个格子中。需要定义训练标签，对9个格子中的每一个指定一个标签$y$，$y= \ \begin{bmatrix} p_{c} \\ b_{x} \\ b_{y} \\ b_{h} \\ b_{w} \\ c_{1} \\ c_{2}\\ c_{3} \\\end{bmatrix}$，边界框的高度用格子总体宽度的比例表示，总的输出维度是3×3×8

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217142001.png" style="zoom:67%;" />

对于图内有多个对象的情况，**YOLO**算法取对象的中点，然后将这个对象分配给包含对象中点的格子。如果使用更精细的网格则多个对象分配到同一个格子的概率会比较小。

该算法显式地输出边界框坐标，可以具有任意宽高比，并且能输出更精确的坐标，不会受到滑动窗口分类器的步长大小限制。其次，这是单次卷积实现，效率很高，可以达到实时识别。。

### 1.3.5 交并比（Intersection over union）

交并比（**loU**）函数计算算法给出的边界框和实际边界框的交集和并集之比，来衡量算法定位精确度

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217142527.png" style="zoom:67%;" />

### 1.3.6 非极大值抑制

目标检测算法可能对同一个对象做出多次检测。使用非极大值抑制可以确保对每个对象只检测一次，并保留最优的边界框。

非极大值抑制的流程：首先找到有着最大$p_{c}$的边界框，然后遍历其余的框，如果和当前最大$p_{c}$框的IOU大于一定阈值，就将框删除。然后逐一检查剩下的边界框，进行相同操作

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217143255.png" style="zoom:67%;" />

### 1.3.7 Anchor Boxes

Anchor Boxes可以使一个格子检测出多个对象

首先需要预先定义多个不同形状的**anchor box**

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217151449.png" style="zoom:67%;" />

然后定义类别标签，假设只定义2个anchor box，使用的向量不再是之前的$\begin{bmatrix} p_{c} & b_{x} &b_{y} & b_{h} & b_{w} & c_{1} & c_{2} & c_{3} \\\end{bmatrix}^{T}$，而实$y=  \begin{bmatrix} p_{c} & b_{x} & b_{y} &b_{h} & b_{w} & c_{1} & c_{2} & c_{3} & p_{c} & b_{x} & b_{y} & b_{h} & b_{w} &c_{1} & c_{2} & c_{3} \\\end{bmatrix}^{T}$，前面的$p_{c},b_{x},b_{y},b_{h},b_{w},c_{1},c_{2},c_{3}$（绿色方框标记的参数）是和**anchor box 1**关联的8个参数，后面的8个参数（橙色方框标记的元素）是和**anchor box 2**相关联。

根据网络给出的边界框和哪个**anchor box**交并比更高，就分配到哪个anchor box里

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217151844.png" style="zoom:67%;" />

**YOLO**算法将前几节的算法组合在一起，将图片分成n*n个网格，指定**anchor box**的数量，使用非极大值抑制去掉冗余的边界框

### 1.3.8 候选区域（Region proposals ）

传统算法的一个缺点是会遍历图片的所有区域，而有些区域是没有任何对象的。而**R-CNN**算法，即带区域的卷积网络，尝试选出一些区域，在这些区域上运行卷积网络分类器是有意义的。

选出候选区域的方法是运行图像分割算法，分割的结果如下图，找出可能存在对象的区域。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20211217192438.png" style="zoom:67%;" />

先找出可能几千个色块，然后在这些色块上放置边界框，运行分类器，这样需要处理的位置可能要少的多，可以减少卷积网络分类器运行时间，比在图像所有位置运行一遍分类器要快。

**Ross Girshik**提出了Fast R-CNN算法，在**R-CNN**算法基础上，用卷积实现了滑动窗法。其问题是得到候选区域的聚类步骤仍然非常缓慢

**Faster R-CNN**使用卷积神经网络，而不是传统的分割算法来获得候选区域色块，结果比**Fast R-CNN**算法快得多。