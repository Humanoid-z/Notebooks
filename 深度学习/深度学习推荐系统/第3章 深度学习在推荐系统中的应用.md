在进入深度学习时代之后，推荐模型主要在以下两方面取得了重大进展。

1. 与传统的机器学习模型相比，深度学习模型的**表达能力更强**，能够挖掘出更多数据中潜藏的模式。
2. 深度学习的**模型结构非常灵活**，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。

# 1 深度学习推荐模型的演化关系

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/20220526202514.png" alt="image-20220526202513902" style="zoom:67%;" />

1. 改变神经网络的复杂程度：从最简单的单层神经网络模型AutoRec （自编码器推荐），到经典的深度神经网络结构Deep Crossing（深度特征交叉），其主要的进化方式在于增加了深度神经网络的层数和结构复杂度。

2. 改变特征交叉方式：这类模型的主要改变在于丰富了深度学习网络中特征交叉的方式。例如，改变了用户向量和物品向量互操作方式的NeuralCF( Neural Collaborative Filtering ，神经网络协同过滤），定义了多种特征向量交叉操作的
   PNN (Product-based Neural Network ，基于积操作的神经网络）模型。

3. 组合模型：这类模型主要是指Wide&Deep 模型及其后续变种Deep&Cross 、DeepFM 等，其思路是通过组合两种不同特点、优势互补的深度学习网络，提升模型的综合能力。

4. FM 模型的深度学习演化版本：传统推荐模型FM 在深度学习时代有了诸多后续版本，其中包括NFM ( Neural Factorization Machine ，神经网络因子分解机）、FNN (Factorization-machine supported Neural Network ，基于因子分解机支持的神经网络）、AFM (Attention neural Factorization Machi肘，注意力因子分解机） 等，它们对FM 的改进方向各不相同。例如， NFM 主要使用神经网络提升FM 二阶部分的特征交叉能力， AFM 是引入了注意力机制的FM 模型， FNN利用FM 的结果进行网络初始化。
5. 注意力机制与推荐模型的结合：这类模型主要是将“注意力机制”应用于深度学习推荐模型中， 主要包括结合了FM 与注意力机制的AFM 和引入了注意力机制的CTR 预估模型DIN ( Deep Interest Network ，深度兴趣网络）。
6. 序列模型与推荐模型的结合：这类模型的特点是使用序列模型模拟用户行为或用户兴趣的演化趋势，代表模型是DIEN( Deep Interest Evolution Network,深度兴趣进化网络）。
7. 强化学习与推荐模型的结合：这类模型将强化学习应用于推荐领域，强调模型的在线学习和实时更新，其代表模型是DRN( Deep Reinforcement Learning Network ，深度强化学习网络）。

# 2 AutoRec——单隐层神经网络推荐模型

AutoRec将自编码器（ AutoEncoder ）的思想和协同过滤结合，提出了一种单隐层神经网络推荐模型。

## 2.1 AutoRec 模型的基本原理

Auto Rec 模型是一个标准的自编码器，它的基本原理是利用协同过滤中的共现矩阵，完成物品向量或者用户向量的自编码。再利用自编码的结果得到用户对物品的预估评分，进而进行推荐排序。

对一个物品i来说，所有m个用户对它的评分可形成一个m 维的向量$r^{(i)}=(R_{1i},...,R_{mi})$，AutoRec 要解决的问题是构建一个重建函数$h(r;\theta)$，使所有该重建函数生成的评分向量与原评分向量的平方残差和最小。

在得到AutoRec 模型的重建函数后，还要经过评分预估和排序的过程才能得到最终的推荐列表。

## 2.2 AutoRec 模型的结构

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/AutoEncoder.png" alt="【全】一文带你了解自编码器（AutoEncoder）" style="zoom:67%;" />

设$\mathbf{R}_{*i}$为评分矩阵的$i^\mathrm{th}$列，未知评分默认置零，神经网络结构定义为：

$h(\mathbf{R}_{*i}) = f(\mathbf{W} \cdot g(\mathbf{V} \mathbf{R}_{*i} + \mu) + b)$

上式中$f(\cdot)$和$g(\cdot)$代表激活函数，$\mathbf{W}$和$\mathbf{V}$为权重矩阵，$\mu$和$b$为偏差。$h( \cdot )$为AutoRec的整个网络。$h(\mathbf{R}_{*i})$的输出为评分矩阵$i^\mathrm{th}$列的重建。

以下目标函数旨在最小化重建误差：

$\underset{\mathbf{W},\mathbf{V},\mu, b}{\mathrm{argmin}} \sum_{i=1}^M{\parallel \mathbf{R}_{*i} - h(\mathbf{R}_{*i})\parallel_{\mathcal{O}}^2} +\lambda(\| \mathbf{W} \|_F^2 + \| \mathbf{V}\|_F^2)$

```python
class AutoRec(nn.Module):
    def __init__(self, num_hidden, num_users, dropout=0.05,mode = 'train'):
        super(AutoRec, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(num_users,num_hidden),
            nn.Sigmoid()
        )
        self.decoder = nn.Linear(num_hidden,num_users)
        self.dropout = nn.Dropout(dropout)
        self.mode = mode

    def forward(self, X):
        hidden = self.dropout(self.encoder(X)) #(b,num_users) ->(b,num_hidden)
        y = self.decoder(hidden) #(b,num_hidden) ->(b,num_users)
        if self.mode=='train':  # Mask the gradient during training
            return y * torch.sign(X) 
        # torch.sign(X):-1 if x < 0, 0 if x==0, 1 if x > 0. 
        # 交互矩阵中未标注的数据为0，用来屏蔽未标注的输入的梯度对模型的影响（否则就会向0靠近）
        else:
            return y
```
## 2.3 基于AutoRec 模型的推荐过程

当输入物品i的评分向量为$r^{(i)}$时，模型的输出向量$h(r^{(i)};\theta)$就是所有用户对物品i的评分预测。

AutoRec 也分为基于物品的AutoRec 和基于用户的AutoRec 。以上介绍的AutoRec 输入向量是物品的评分向量，因此可称为I-AutoRec，如果换做把用户的评分向量作为输入向量，则得到U-AutoRec 。在进行推荐列表生成的过程中，**U-AutoRec 相比1-AutoR目的优势在于仅需输入一次目标用户的用户向量，就可以重建用户对所有物品的评分向量。也就是说，得到用户的推荐列表仅需一次模型推断过程； 其劣势是用户向量的稀疏性可能会影响模型效果**。

## 2.4AutoRec模型的特点和局限性

Auto Re c 模型从神经网络的角度出发， 使用一个单隐层的Auto Encoder 泛化用户或物品评分，使模型具有一定的泛化和表达能力。由于AutoRec 模型的结构比较简单，使其存在一定的表达能力不足的问题。

在模型结构上， AutoRec 模型和后来的词向量模型（ Word2 v e c ）完全一致。

# 3Deep Crossing 模型——经典的深度学习架构

相比AutoRec模型过于简单的网络结构带来的一些表达能力不强的问题，Deep Crossing 模型完整地解决了从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合等一系列深度学习在推荐系统中的应用问题，为后续的研究打下了良好的基础。

针对该使用场景，微软使用的特征特征可以分为三类：一类是可以被处理成one-hot 或者multi-hot 向量的**类别型特征**，包括用户搜索词(query ）、广告关键词（ keyword ）、广告标题（ title ）、落地页（ landing page ）、匹配类型（ match type ）；一类是**数值型特征**，微软称其为计数型（ counting ）特征，包括点击率、预估点击率（ click prediction ）；一类是**需要进一步处理的特征**，包括广告计划（ campaign ）、曝光样例（ impression ）、点击样例（ click ）等。严格地说，这些都不是独立的特征，而是一个特征的组别，需要进一步处理。例如，可以将广告计划中的预算（ budget ）作为数值型特征，而广告计划的id 则可以作为类别型特征。

## 3.1Deep Crossing 模型的应用场景

DeepCrossing模型的应用场景是微软搜索引擎Bing中的搜索广告推荐场景。尽可能地增加搜索广告的点击率，准确地预测广告点击率，并以此作为广告排序的指标之一是Deep Crossing 模型的优化目标。

## 3.2Deep Crossing 模型的网络结构

为完成端到端训练， Deep Crossing 模型要在其内部网络中解决如下问题。

1. 离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决稀疏特征向量稠密化的问题。
2. 如何解决特征自动交叉组合的问题。
3. 如何在输出层中达成问题设定的优化目标。

Deep Crossing 模型分别设置了不同的神经网络层来解决上述问题。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DeepCrossing.png" alt="image-20220612201444656" style="zoom:67%;" />

Embedding 层： Embedding 层的作用是将稀疏的类别型特征转换成稠密的Embedding 向量。每一个特征（如Feature#1 ，这里指的是经one-hot 编码后的稀疏特征向量） 经过Embedding 层后， 会转换成对应的Embedding 向量（ 如Embedding#1 ）。Feature#2 实际代表数值型特征，数值型特征不需要经过Embedding 层，直接进入Stacking 层。

Stacking 层： Stacking 层的作用 是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接(concatenate)层。

Multiple Residual Units 层： 该层的主要结构是多层感知机，相比标准的以
感知机为基本单元的神经网络， Deep Crossing 模型采用了多层残差网络( Multi-Layer Residual Network ）作为MLP 的具体实现。

通过多层残差网络对特征向量各个维度进行充分的交叉组合，使模型能够抓
取到更多的非线性特征和组合特征的信息，进而使深度学习模型在表达能力上较
传统机器学习模型大为增强。

## 3.3 Deep Crossing 模型对特征交叉方法的革命

Deep Crossing 模型中没有任何人工特征工程的参与，原始特征经Embedding 后输入神经网络层，将全部特征交叉的任务交给模型。相比之前介绍的FM 、FFM 模型只具备二阶特征交叉的能力， Deep Crossing 模型可以通过调整神经网络的深度进行特征之间的“深度交叉”

# 4 NeuralCF 模型——CF 与深度学习的结合

从深度学习的视角看待矩阵分解模型，矩阵分解层的用户隐向量和物品隐向量可以看作一种Embedding 方法。最终的“ Scoring 层”就是将用户隐向量和物品隐向量进行内积操作后得到“相似度”。

在实际使用矩阵分解来训练和评估模型的过程中，矩阵分解的模型结构比较简单，模型容易处于欠拟合的状态，无法对优化目标进行有效的拟合。这就要求模型有更强的表达能力，因此产生了Neural CF 模型。

Neural CF 模型仅使用用户向量和物品向量，并没有引入更多其他类型的特征，这在实际应用中无疑浪费了其他有价值的信息。

## 4.1NeuralCF 模型的结构

NeuralCF 用“多层神经网络＋输出层”的结构替代了矩阵分解模型中简单的内积操作。一是让用户向量和物品向量做更充分的交叉，得到更多有价值的特征组合信息；二是引人更多的非线性特征，让模型的表达能力更强。

![image-20220612210302080](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/NeuralCF.png)



# 5 PNN 模型——加强特征交叉能力

Neural CF 模型的主要思想是利用多层神经网络替代经典协同过滤的点积操作，加强模型的表达能力。但Neural CF 模型只提到了用户向量和物品向量两组特征向量，如果加入多组特征向量又该如何设计特征交互的方法呢？ PNN模型给出了特征交互方式的几种设计思路。

# 5.1PNN模型的网络架构

相比Deep Crossing 模型， PNN 模型在输入、Embedding 层、多层神经网络，以及最终的输出层部分并没有结构上的不同，唯一的区别在于PNN模型用乘积层（ Product Layer ）代替了Deep Crossing 模型中的Stacking 层。也就是说，不同特征的Embedding 向量不再是简单的拼接，而是用Product 操作进行两两交互，更有针对性地获取特征之间的交叉信息。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/PNN.png" alt="image-20220614090609415" style="zoom: 50%;" />

## 5.2 Product 层的多种特征交叉方式

PNN模型的乘积层由线性操作部分（图3-12 中乘积层的z 部分，对各特征向量进行线性拼接）和乘积操作部分（图3-12 中乘积层的p 部分）组成。其中乘积特征交叉部分又分为内积操作和外积操作，使用内积操作的PNN 模型被称为IPNN，使用外积操作的PNN 模型被称为OPNN。

外积操作是对输入特征向量$f_i,f_j$的各维度进行两两交叉，生成特征交叉矩
阵$f_if^{T}_j$

这样的外积操作会直接将问题的复杂度从原来的M提升到$M^2$，为了在一定程度上减小模型训练的负担， PNN 模型的论文中介绍了一种降维的方法，就是把所有两两特征Embedding 向量外积互操作的结果叠加（ Superposition ），形成一个叠加外积互操作矩阵p

$p = \sum_{i=1}^N\sum_{j=1}^Nf_if^{T}_j$

叠加矩阵p 的最终形式类似于让所有特征Embedding 向量通过一个平均池化（相加后没有除以总数）层后，再进行外积互操作。

在实际应用中，还应对平均池化的操作谨慎对待。==因为把不同特征对应维度进行平均，实际上是假设不同特征的对应维度有类似的含义==。但显然，如果一个特征是“年龄”，一个特征是“地域”，那么这两个特征在经过各自的Embedding层后，二者的Embedding 向量不在一个向量空间中，显然不具备任何可比性。这时，把二者平均起来，会模糊很多有价值的信息。==平均池化的操作经常发生在同类Embedding 上，例如，将用户浏览过的多个物品的Embedding 进行平均。==因此，PNN 模型的外积池化操作也需要谨慎，在训练效率和模型效果上进行权衡。

## 5.3PNN模型的优势和局限性

PNN 的结构特点在于强调了特征Embedding 向量之间的交叉方式是多样化的，相比于简单的交由全连接层进行无差别化的处理， PNN 模型定义的内积和外积操作显然更有针对性地强调了不同特征之间的交互，从而让模型更容易捕获特征的交叉信息。但PNN 模型同样存在着一些局限性，例如在外积操作的实际应用中，为了优化训练效率进行了大量的简化操作。此外，对所有特征进行无差别的交叉，在一定程度上忽略了原始特征向量中包含的有价值信息。

# 6 Wide&Deep 模型——记忆能力和泛化能力的综合

Wide&Deep 模型的主要思路正如其名， 是由单层的Wide 部分和多层的Deep 部分组成的混合模型。其中， Wide 部分的主要作用是让模型具有较强的“记忆能力”（memorization); Deep 部分的主要作用是让模型具有“泛化能力”（generalization ），正是这样的结构特点，使模型兼具了逻辑回归和深度神经网络的优点——能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力，不仅在当时迅速成为业界争相应用的主流模型，而且衍生出了大量以Wide&Deep 模型为基础结构的混合模型，影响力一直延续到至今。

## 6.1 模型的记忆能力与泛化能力

“记忆能力”可以被理解为模型直接学习井利用历史数据中物品或者特征的“共现频率”的能力。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力” 。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似于“如果点击过A ，就推荐B” 这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。

“泛化能力”可以被理解为模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。

## 6.2Wide&Deep 模型的结构

![image-20220617134908850](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/wide%2526deep.png)

Wide&Deep 模型把单输入层的Wide 部分与由Embedding 层和多隐层组成的Deep 部分连接起来， 一起输入最终的输出层。单层的Wide 部分善于处理大量稀疏的id 类特征； Deep 部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式。最终，利用逻辑回归模型，输出层将Wide部分和Deep 部分组合起来，形成统一的模型。

![image-20220617135048985](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/wide%2526deep2.png)

Deep 部分的输入是全量的特征向量， 需要经过Embedding 层输入连接层，拼接成1200 维的Embedding 向量，再依次经过3 层ReLU 全连接层，最终输入LogLoss 输出层。

Wide 部分的输入仅仅是已安装应用和曝光应用两类特征，其中已安装应用代表用户的历史行为，而曝光应用代表当前的待推荐应用。选择这两类特征的原因是充分发挥Wide 部分“记忆能力”强的优势。

Wide 部分组合两个特征的函数被称为交叉积变换（ Cross Product Transformation ）函数，其定义如下：

$\phi_k(\mathbf{X})=\prod_{i=1}^dx_i^{c_{ki}}\qquad c_{ki} \in\{0,1\}$

$c_{ki}$是一个布尔变量，当第i个特征属于第k个组合特征时，$c_{ki}$的值为1，否则为0; $x_i$是第i 个特征的值。例如，对于“AND(user_installed_app=netflix ,impression_app=pandora)”这个组合特征来说，只有当“user_installed app=netflix”和“ impression app=pandora”这两个特征同时为1 时，其对应的交叉积变换层的结果才为1 ，否则为0 。

在通过交叉积变换层操作完成特征组合之后，Wide 部分将组合特征输入最终的LogLoss 输出层，与Deep 部分的输出一同参与最后的目标拟合，完成Wide与Deep 部分的融合。

## 6.3Wide&Deep 模型的进化——Deep&Cross 模型

Deep&Cross 模型的主要思路是使用Cross 网络替代原来的Wide 部分。

![image-20220617145032580](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/Deep%2526Cross.png)

设计Cross 网络的目的是增加特征之间的交互力度，使用多层交叉层对输入向量进行特征交叉。假设第$l$层交叉层的输出向量为$x_l$ ，那么第$l+1$层的输出向量如下所示。

$x_{l+1}=x_0x_l^TW_l+b_l+x_l$

# 7 FM 与深度学习模型的结合

## 7.1FNN——用FM的隐向量完成Embedding层初始化

FNN模型的结构初步看是一个类似Deep Crossing 模型的经典深度神经网络，从稀疏输入向量到稠密向量的转换过程也是经典的Embedding层的结构。

![image-20220617155005484](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/FNN.png)

FNN主要还是对Embedding 层的改进。在神经网络的参数初始化过程中，往往采用随机初始化这种不包含任何先验信息的初始化方法。由于Embedding 层的输入极端稀疏化，导致Embedding 层的收敛速度非常缓慢。再加上Embedding层的参数数量往往占整个神经网络参数数量的大半以上，因此模型的收敛速度往往受限于Embedding 层。

针对Embedding 层收敛速度的难题， FNN 模型的解决思路是用FM 模型训练好的各特征隐向量初始化Embedding 层的参数，相当于在初始化神经网络参数时，已经引入了有价值的先验信息。也就是说，神经网络训练的起点更接近目标最优点，自然加速了整个神经网络的收敛过程。

![image-20220617160314882](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/FM_init_embedding.png)

## 7.2 Deep FM——用FM 代替Wide 部分

![image-20220619161129797](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DeepFM.png)

DeepFM 对Wide&Deep 模型的改进之处在于，它用FM 替换了原来的Wide部分， 加强了浅层网络部分特征组合的能力。左边的FM 部分与右边的深度神经网络部分共享相同的Embedding 层。左侧的FM 部分对不同的特征域的Embedding 进行了两两交叉，也就是将Embedding向量当作原FM 中的特征隐向量。最后将FM 的输出与Deep 部分的输出一同输入最后的输出层，参与最后的目标拟合。

## 7.3NFM——FM 的神经网络化尝试

NFM 模型的主要思路是用神经网络替代原FM 中二阶隐向量内积的部分

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/NFM.png" alt="image-20220624205045539" style="zoom: 50%;" />

NFM 网络架构的特点非常明显，就是在Embedding 层和多层神经网络之间
加入特征交叉池化层

![image-20220624210158701](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/Bi-InteractionPoolingLayer.png)

$\odot$代表两个向量的元素积操作，即两个长度相同的向量对应维相乘得到元素积向量。

在进行两两Embedding 向量的元素积操作后，对交叉特征向量取和，得到池化层的输出向量。

NFM 架构图省略了其一阶部分。如果把NFM 的一阶部分视为一个线性模型，那么NFM 的架构也可以视为Wide&Deep 模型的进化。相比原始的Wide&Deep 模型， NFM 模型对其Deep 部分加入了特征交叉池化层，加强了特征交叉。

## 7.4 基于FM的深度学习模型的优点和局限性

本节介绍了FNN 、DeepFM 、NFM 三个结合FM 思路的深度学习模型。它们的特点都是在经典多层神经网络的基础上加入有针对性的特征交叉操作，让模型具备更强的非线性表达能力。

沿着特征工程自动化的思路，深度学习模型从PNN 一路走来，经过了Wide&Deep 、Deep&Cross 、FNN 、DeepFM 、NFM 等模型，进行了大量的、基于不同特征互操作思路的尝试。但特征工程的思路走到这里几乎已经穷尽了可能的尝试， 模型进一步提升的空间非常小，这也是这类模型的局限性所在。

从这之后，越来越多的深度学习推荐模型开始探索更多“结构”上的尝试，诸如注意力机制、序列模型、强化学习等在其他领域大放异彩的模型结构也逐渐进入推荐系统领域，并且在推荐模型的效果提升上成果显著。

# 8 注意力机制在推荐模型中的应用

## 8.1 AFM——引入注意力机制的FM

AFM 模型可以被认为是7.3节介绍的NFM 模型的延续。在NFM 模型中，不同域的特征Embedding 向量经过特征交叉池化层的交叉，将各交叉特征向量进行“加和”，输入最后由多层神经网络组成的输出层。问题的关键在于加和池化( Sum Pooling ）操作，相当于“一视同仁”地对待所有交叉特征，不考虑不同特征对结果的影响程度， 事实上消解了大量有价值的信息。

“注意力机制”基于假设一一不同的交叉特征对于结果的影响程度不同， 以更直观的业务场景为例， 用户对不同交叉特征的关注程度应是不同的。举例来说，如果应用场景是预测一位男性用户是否购买一款键盘的可能性，那么“性别＝男且购买历史包含鼠标” 这一交叉特征，很可能比“性别＝男且用户年龄＝30”这一交叉特征更重要，模型投入了更多的“注意力” 在前面的特征上。

AFM 模型引人注意力机制是通过在特征交叉层和最终的输出层之间加入注意力网络（ Attention Net ）实现的。AFM 的模型结构图如图所示，注意力网络的作用是为每一个交叉特征提供权重，也就是注意力得分。

![image-20220627185719500](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/AFM.png)

同NFM 一样， AFM 的特征交叉过程同样采用了元素积操作，在加入注意力得分后的池化过程如下所示。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/AFM_pooling.png" alt="image-20220627190653156" style="zoom:50%;" />

对注意力得分的来说，最简单的方法就是用一个权重参数来表示，但为了防止交叉特征数据稀疏问题带来的权重参数难以收敛， AFM 模型使用了一个在两两特征交叉层（ Pair-wise Interaction Layer ）和池化层之间的注意力网络来生成注意力得分。

该注意力网络的结构是一个简单的单全连接层加softmax 输出层的结构，如下所示。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/AFM_attention.png" alt="image-20220627191211127" style="zoom:50%;" />

## 8.2 DIN——引入注意力机制的深度学习网络

阿里巴巴提出的DIN 模型的应用场景是阿里巴巴的电商广告推荐，因此在计算一个用户u 是否点击一个广告a 时，模型的输入特征自然分为两大部分：一部分是用户u的特征组，另一部分是候选广告a 的特征组。无论是用户还是广告，都含有两个非常重要的特征一一商品id (good id ）和商铺id (shop id ）。用户特征里的商品id 是一个序列，代表用户曾经点击过的商品集合，商铺id 同理；而广告特征里的商品id 和商铺id 就是广告对应的商品id 和商铺id （阿里巴巴平台上的广告大部分是参与推广计划的商品）。

在原来的基础模型中用户特征组中的商品序列和商铺序列经过简单的平均池化操作后就进入上层神经网络进行下一步训练，序列中的商品既没有区分重要程度，也和广告特征中的商品id 没有关系。

![image-20220627215545414](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/Base_DIN.png)

DIN模型利用候选商品和历史行为商品之间的相关性计算出一个权重，这个权重就代表了“ 注意力”的强弱，注意力部分的形式化表达如下。

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DIN_attention.png" alt="image-20220627225505473" style="zoom:50%;" />

其中，$V_u$是用户的Embedding 向量，$V_a$是候选广告商品的Embedding向量，
$V_i$是用户u 的第i次行为的Embedding 向量。这里用户的行为就是浏览商品或店
铺，因此行为的Embedding向量就是那次浏览的商品或店铺的Embedding向量。

$g(V_i,V_a)$函数采用一个注意力激活单元来生成注意力得分。这个注意力激活单元本质上也是一个小的神经网络，输入层是两个Embedding 向量，经过元素减(element-wise minus)操作后，与原Embedding 向量一同连接后形成全连接层的输入，最后通过单神经元输出层生成注意力得分。

# 9 DIEN——序列模型与推荐系统的结合

DIEN作为DIN 模型的演化版本，模型的应用场景和DIN 完全一致，其创新在于用序列模型模拟了用户兴趣的进化过程。

## 9. 1 DIEN模型的架构

模型仍是输入层＋Embedding 层＋连接层＋多层全连接神经网络＋输出层的整体架构。图中彩色的“兴趣进化网络”被认为是一种用户兴趣的Embedding 方法，它最终的输出是$h'(T)$这个用户兴趣向量。DIEN模型的创新点在于如何构建“兴趣进化网络” 。

![DIEN 整体架构](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DIEN_en.png)

兴趣进化网络分为三层，从下至上依次是：

( 1 ）行为序列层（ Behavior Layer，浅绿色部分）：其主要作用是把原始的id类行为序列转换成Embedding 行为序列。

( 2 ）兴趣抽取层（ Interest Extractor Layer ，米黄色部分）：其主要作用是通过模拟用户兴趣迁移过程，抽取用户兴趣。

( 3 ）兴趣进化层（ Interest Evolving Layer ，浅红色部分）：其主要作用是通过在兴趣抽取层基础上加入注意力机制，模拟与当前目标广告相关的兴趣进化过程。在兴趣进化网络中，行为序列层的结构与普通的Embedding 层是一致的，模拟用户兴趣进化的关键在于“兴趣抽取层”和“兴趣进化层” 。

## 9.2兴趣抽取层的结构

兴趣抽取层的基本结构是GRU ( Gated Recurrent Unit ，门循环单元）网络。相比传统的序列模型RNN (Recurrent Neural Network ，循环神经网络）和LSTM( Long Short-Term Memory ，长短期记忆网络）， GRU 解决了RNN 的梯度消失问
题（ Vanishing Gradients Problem ）。与LSTM 相比， GRU 的参数数量更少，训练收敛速度更快，因此成了DIEN 序列模型的选择。

每个GRU 单元的具体形式如下。
$$
u_t=\sigma(W^ui_t+U^uh_{t-1}+b^u) \\
r_t=\sigma(W^ri_t+U^rh_{t-1}+b^r) \\
\tilde{h}_t=\tanh(W^hi_t+r_t\circ h_{t-1}+b^h) \\
h_t=(1-u_t)\circ h_{t-1}+u_t\circ \tilde{h}_t \\
$$
其中， $\sigma$是Sigmoid 激活函数，$\circ$是元素积操作，$W^u,W^r,W^h,U^z,U^r,U^h$是6组需要学习的参数矩阵，$i_t$是输入状态向量，也就是行为序列层的各行为Embedding 向量b(t)，$h_t$是GRU 网络中第t个隐状态向量。

经过由GRU组成的兴趣抽取层后，用户的行为向量b(t)被进一步抽象化，形成了兴趣状态向量h(t)。理论上，在兴趣状态向量序列的基础上， GRU 网络已经可以做出下一个兴趣状态向量的预测，但DIEN 却进一步设置了兴趣进化层。

## 9.3兴趣进化层的结构

DIEN 兴趣进化层相比兴趣抽取层最大的特点是加入了注意力机制。这一特点与DIN 的一脉相承。兴趣进化层注意力得分的生成过程与DIN 完全一致，都是当前状态向量与目标广告向量进行互作用的结果。也就是说， DIEN 在模拟兴趣进化的过程中，需要考虑与目标广告的相关性。

在兴趣抽取层之上再加上兴趣进化层就是为了更有针对性地模拟与目标广告相关的兴趣进化路径。由于阿里巴巴这类综合电商的特点，用户非常有可能同时购买多品类商品，例如在购买“机械键盘”的同时还在查看“衣服”品类下的商品，那么这时注意力机制就显得格外重要了。当目标广告是某个电子产品时，用户购买“机械键盘”相关的兴趣演化路径显然比购买“衣服”的演化路径重要，这样的筛选功能兴趣抽取层没有。

兴趣进化层完成注意力机制的引入是通过AUGRU（GRU with Attentional
Update gate ，基于注意力更新门的GRU结构）， AUGRU在原GRU 的更新门的结构上加入了注意力得分，具体形式如下所示。
$$
\tilde{u}'_t=a_t\cdot u'_t \\
h'_t=(1-\tilde{u}'_t)\circ h'_{t-1}+\tilde{u}'_t\circ \tilde{h}'_{t}
$$
AUGRU 在原始的$u'_t$【原始更新门向量】基础上加入了注意力得分$a_t$，注意力得分的生成方式与DIN 模型中注意力激活单元的基本一致。

# 10强化学习与推荐系统的结合

强化学习（ Reinforcement Learning ）是近年来机器学习领域非常热门的研究话题，它的研究起源于机器人领域，针对智能体（ Agent ）在不断变化的环境( Environment ）中决策和学习的过程进行建模。在智能体的学习过程中，会完成收集外部反馈（ Reward ），改变自身状态（ State ），再根据自身状态对下一步的行动（ Action ）进行决策，在行动之后持续收集反馈的循环，简称“行动－反馈－状态更新”的循环。

2018 年由宾夕法尼亚州立大学和微软亚洲研究院的学者提出的推荐领域的强化学习模型DRN就是一次将强化学习应用于新闻推荐系统的尝试。

## 10.1深度强化学习推存系统框架

![image-20220702153333877](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/RL_recsys.png)

智能体：推荐系统本身，它包括基于深度学习的推荐模型、探索(explore)策略， 以及相关的数据存储（ memory ）。

环境： 由新闻网站或App 、用户组成的整个推荐系统外部环境。在环境中，用户接收推荐的结果并做出相应反馈。

行动：对一个新闻推荐系统来说，“行动”指的就是推荐系统进行新闻排序后推送给用户的动作。

反馈：用户收到推荐结果后，进行正向的或负向的反馈。例如，点击行为被认为是一个典型的正反馈，曝光未点击则是负反馈的信号。此外，用户的活跃程度，用户打开应用的间隔时间也被认为是有价值的反馈信号。

状态：状态指的是对环境及自身当前所处具体情况的刻画。在新闻推荐场景中，状态可以被看作已收到所有行动和反馈，以及用户和新闻的所有相关信息的特征向量表示。站在传统机器学习的角度，“状态”可以被看作已收到的、可用于训练的所有数据的集合。

在这样的强化学习框架下，模型的学习过程可以不断地迭代，迭代过程主要有如下几步：

( 1 ）初始化推荐系统（智能体）。

( 2 ）推荐系统基于当前已收集的数据（状态）进行新闻排序（行动），并推送到网站或App （环境）中。

( 3 ）用户收到推荐列表，点击或者忽略（反馈）某推荐结果。

( 4 ）推荐系统收到反馈，更新当前状态或通过模型训练更新模型。

( 5 ）重复第2 步。

强化学习相比传统深度模型的优势就在于强化学习模型能够进行“在线学习”，不断利用新学到的知识更新自己，及时做出调整和反馈。

## 10.2 深度强化学习推荐模型

智能体部分是强化学习框架的核心，对推荐系统这一智能体来说，推荐模型是推荐系统的“大脑” 。在DRN 框架中，扮演“大脑”角色的是Deep Q-Network（深度Q 网络，简称DQN ），其中Q 是Quality 的简称，指通过对行动进行质量评估，得到行动的效用得分，以此进行行动决策。

DQN 的网络结构如下所示，在特征工程中套用强化学习状态向量和行动向量的概念，把用户特征和环境特征归为状态向量，因为它们与具体的行动无关；把用户－新闻交叉特征和新闻特征归为行动特征，因为其与推荐新闻这一行动相关。

![DQN](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DQN.png)

用户特征和环境特征经过左侧多层神经网络的拟合生成价值（ value ）得分
$V(s)$ ，利用状态向量和行动向量生成优势（ advantage ）得分$A(s)$，最后把两部分得分综合起来，得到最终的质量得分Q(s,a) 。

## 10.3 DRN 的学习过程

DRN 的学习过程是整个强化学习推荐系统框架的重点，正是由于可以在线更新，才使得强化学习模型相比其他“静态”深度学习模型有了更多实时性上的优势。下图以时间轴的形式形象地描绘了DRN 的学习过程。

![image-20220702155935733](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DRN.png)

按照从左至右的时间顺序，依次描绘DRN 学习过程中的重要步骤。

( 1 ）在离线部分，根据历史数据训练好DQN 模型，作为智能体的初始化模型。

( 2 ）在$t_1\rightarrow t_2$ 阶段，利用初始化模型进行一段时间的推送（ push ）服务， 积累反馈（ feedback ）数据。

( 3 ）在$t_2$时间点，利用$t_1\rightarrow t_2$阶段积累的用户点击数据，进行模型微更新（ minor update ）。

( 4 ）在$t_4$时间点，利用$t_1\rightarrow t_4$阶段的用户点击数据及用户活跃度数据进行模
型的主更新（ major update ）。

( 5 ） 重复第2-4 步。

在第4 步中出现的模型主更新操作可以理解为利用历史数据的重新训练，用训练好的模型替代现有模型。那么在第3 步中提到的模型微调使用一种新的在线训练方法一一竞争梯度下降算法（ Dueling Bandit Gradient Descent Algorithm ） 。

## 10.4DRN 的在线学习方法——竞争梯度下降算法

竞争梯度下降算法的流程如图所示

<img src="https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/Dueling_Bandit_Gradient_Descent_Algorithm.png" alt="image-20220702161247377" style="zoom:50%;" />

其主要步骤如下：

( 1 ）对于已经训练好的当前网络$Q$，对其模型参数$W$添加一个较小的随机扰动$\Delta W$，得到新的模型参数$\widetilde{W}$ ，这里称$\widetilde{W}$对应的网络为探索网络。

( 2 ）对于当前网络$Q$ 和探索网络$\widetilde{Q}$ ，分别生成推荐列表$L$和$\widetilde{L}$ ，用**Interleaving**将两个推荐列表组合成一个推荐列表后推送给用户。

( 3 ）实时收集用户反馈。如果探索网络$\widetilde{Q}$生成内容的效果好于当前网络$Q$,则用探索网络代替当前网络，进入下一轮迭代；反之则保留当前网络。

在第1步中，由当前网络$Q$生成探索网络$\widetilde{Q}$ ,产生随机扰动的公式如下所示。

$\Delta W=a\cdot rand(-1,1)\cdot W$

其中， α是探索因子，决定探索力度的大小。

DRN 的在线学习过程利用了“探索”的思想，其调整模型的粒度可以精细到每次获得反馈之后，这一点很像随机梯度下降的思路，虽然一次样本的结果可能产生随机扰动，但只要总的下降趋势是正确的，就能通过海量的尝试最终达到最优点。DRN 正是通过这种方式，让模型时刻与最“新鲜”的数据保持同步，将最新的反馈信息实时地融入模型中。