## 2.2 图神经网络：前沿

*图神经网络:图分类与链接预测*。由于GNN模型中的每一层都只产生节点级表示，因此需要图池化层来基于节点级表示进一步计算图级表示。图级表示概括了输入图结构的关键特征，是图分类的关键组成部分。根据图池层的学习技术，这些方法通常可以分为四类:简单平池化(Duvenaud 等人，2015年;Mesquita等人，2020年)，基于注意力的汇集(Lee等人，2019d;Huang 等,2019d)，基于簇的池化(Ying等，2018c)，以及其他类型的池化(Zhang等，2018f;Bianchi等人，2020;Morris等人，2020b)。除了图分类，另一个长期存在的图学习问题是链接预测任务，它旨在预测任何对节点之间缺失的或未来的链接。由于GNN可以联合学习图结构和附加信息(side information如节点和边特征)，因此在链路预测方面比其他传统的图学习方法有很大的优势。对于链路预测的学习类型，基于节点的方法(Kipf和Welling, 2016)和基于子图的方法(Zhang和Chen, 2018a)，是两种流行的基于GNN的方法。

*图神经网络:图生成与图变换*。在图上建立概率模型的图生成问题是一个经典的研究问题，它位于概率论和图论的交叉点上。近年来，人们对开发基于gnn等图技术的现代深度学习的深度图生成模型越来越感兴趣。这些深度模型已经被证明是捕获图数据中复杂依赖关系和生成更真实的图的更成功的方法。受变分自编码(VAE) (Kingma和Welling, 2013)和生成对抗网络(Goodfellow等，2014a) (Goodfellow等，2014b)的巨大成功的鼓舞，有三种具有代表性的基于GNN的学习范式用于图生成，包括GraphVAE方法(Jin等，2018b;Simonovsky和Komodakis, 2018;Grover等人，2019年)，GraphGAN方法(De Cao和Kipf, 2018;You等人，2018a)和深度自回归方法(Li等人，2018d;You等人，2018b;Liao等，2019a)。图转换问题可以表述为一个条件图生成问题，其目标是学习输入源图和输出目标图之间的转化映射(Guo等人，2018b)。这种学习问题在其他领域也经常出现，如自然语言处理领域的机器翻译问题和计算机视觉领域的图像风格迁移问题。根据转换的图信息的类型，这个问题一般可以分为四类，包括节点级转换；边级转换，节点与边协变换和图涉及变换。

*图神经网络:图匹配与图结构学习*。图匹配问题是寻找两个输入图之间的对应关系，这是一个在各种研究领域被广泛研究的问题。通常情况下，图匹配问题被认为是NP-hard ，这使得该问题在计算上难以精确和最优地解决现实世界大规模问题。由于GNN具有很强的表达能力，开发基于GNN的多种图匹配方法以提高匹配精度和效率得到了人们更多的注意。图匹配问题的目的是在不改变两个图结构的情况下度量它们之间的相似度。图结构学习的目的是通过联合学习隐式图结构和图节点表示来生成一个优化的图结构。与通常有噪声或不完整的原图相比，学习后的图结构通常可以被视为一种变换。当没有提供初始图，而数据矩阵显示数据点之间的相关性时，也可以使用图结构学习。

*动态图神经网络与异构图神经网络*。在现实世界的应用中，图节点(实体)和边(关系)经常随着时间的推移而变化，这自然就产生了动态图。不幸的是，各种gnn不能直接应用于动态图，在动态图中，对图的演变建模对于做出准确的预测至关重要。一种简单但通常有效的方法是将动态图转换为静态图，这会导致潜在的信息丢失。对于动态图的类型，主要有两类基于GNN的方法，包括离散时间动态图的GNN和连续时间动态图的GNN。另外在实际应用中另一种流行的图类型是由不同类型的图节点和边组成的异构图。为了在异构图中充分利用这些信息，不同的GNN对于同构图不适用。因此，一个新的研究方向致力于开发各种异构图神经网络，包括基于消息传递的方法，基于编码器-解码器的方法和基于对抗性的方法。

*图神经网络：AutoML与自监督学习*。自动化机器学习(AutoML)最近在研究和工业界引起了极大的关注，其目标是应对耗时的人工调优过程的巨大挑战，特别是对于复杂的深度学习模型。AutoML的这一波研究也影响了自动识别优化GNN模型架构和训练超参数的研究工作。现有的研究大多集中在两种架构的搜索空间(Gao等人，2020b;Zhou等人，2019a)或训练超参数搜索空间。gnn的另一个重要研究方向是解决大多数深度学习模型需要大量标注数据的局限性。因此，研究人员提出了一种基于非标记数据设计和利用领域特定前置任务来预训练GNN模型的自监督学习方法。