# Deep Convolutional Inverse Graphics Network（深度卷积逆图形网络）

# 摘要

本文提出的深度卷积逆图形网络 (DC-IGN)能够学习一种图片的可解释性表示，这种表示不受旋转和光线变换的影响。DC-IGN模型由卷积和逆卷积操作组成，使用随机梯度变分贝叶斯算法。模型可以为相同物体生成姿势和光照不同的新图像。

# 1 介绍

计算机图形学使用一个包含场景(图形代码)和图像的组合描述，两部分图形代码通常是分离的，以允许通过对对象位置、姿势、照明、纹理和形状等变换的细粒度控制来渲染场景。

DC-IGN模型结构如下：

![image-20220717165030129](https://raw.githubusercontent.com/SNIKCHS/MDImage/main/img/DC-IGN.png)

结构与变分自编码器VAE类似。Encoder部分由几层卷积和最大池化组成，解码器有几层反池化(使用最近邻上采样)和（逆）卷积。

在训练过程中，数据x通过Encoder产生后验近似$Q(z_i|x)$，$z_i$包含场景的隐变量如姿势，光线，纹理或形状。为了学习参数，梯度使用以下变分函数进行随机梯度下降：$-log(P(x|z_i))+KL(Q(z_i|x)||P(z_i))$

可以通过将一些生效与未生效的变换组合进一个batch来强迫DC-IGN学习一种解耦的表示。

在测试过程中，数据x可以通过编码器得到隐变量$z_i$。通过操作适当的图形代码组$(z_i)$，图像可以被重新渲染成有不同的视角、光照条件、形状变化等。

# 使用特定变换进行训练

本文直接针对解耦设计了训练步骤：设计一些mini-batch，一个batch内只有一种场景变量发生变化（方位角、仰角、光源的方位角），这些变换可能在现实世界中发生，称为外部变量，被表示为编码的$z_{1,2,3}$部分。同时设计另一些mini-batch，这些batch内保证上面提到的三个外部变量固定不变，但是改变所有面部的其他特征。这些描述身份、性状、表情等的内部变量由剩下的隐变量$z_{[4,2000]}$表示。以上两类mini-batch在训练时随机穿插在一起。

具体步骤如下：

1. 随机从【方位角，仰角，光源方位角，内部变量】选择一种隐变量$z_{train}$
2. 随机选择一个只有$z_{train}$对应变量发生变化的mini-batch
3. 获得mini-batch中每一个样本的隐变量$z^k$
4. 计算这些隐变量在整个batch中的平均值
5. 在将编码器的输出送入解码器前，把所有$z_i≠z_{train}$的$z_i$用他们在batch中的平均值替换
6. 在解码器中根据SGVB计算重构误差并进行反向传播
7. 把所有$z_i≠z_{train}$的$z_i$的梯度用其与平均值的差值替换，$z_{train}$的梯度不变
8. 使用修改后的梯度在encoder进行反向传播

第5步的内在含义是：与这些隐变量$z_i≠z_{train}$对应的图像变量(如人脸的身份)在整个batch都没有变化。

通过在整个batch中保持这些输出不变，迫使解码器仅利用单个神经元$z_{train}$的变化来重建batch中所有的变化。（例如通过改变方位角导致图片的全部变化范围）。在反向传播步骤中只有$z_{train}$收到了来自重建误差的梯度，而$z_i≠z_{train}$的梯度使它们更接近平均值。

这种训练方式使得网络的隐变量有很强的等变性，有助于从编码器中提取真实生成参数的值(如人脸的真实角度)。