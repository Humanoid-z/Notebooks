# 用于分子图生成的联合树变分自编码器

# 摘要

我们试图根据特定的化学性质自动化设计分子。该任务涉及分子图的连续嵌入和生成。主要的贡献是直接实现分子图的生成，以前的工作是生成线性SMILES字符串而不是分子图。我们的联合树变分自编码器通过两个阶段生成分子图，首先在化学子结构上生成一个树型结构的支架，然后通过图消息传递网络将它们组合成一个分子。这种方法允许我们在每一步都保持化学有效性的同时增量地扩展分子。我们在从分子生成到优化的多个任务上评估了我们的模型。在这些任务中，我们的模型比以前最先进的基线有显著的优势。

# 1 引言

之前的药物设计工作将图生成任务定义为字符串生成问题，试图回避直接生成图。这些模型首先生成SMILES，一种在化学中用于描述分子结构的线性字符串符号。可以通过确定性映射将SMILES字符串转换为图(如使用RDKit)。然而，这种设计有两个关键的限制。首先，SMILES表示不是为了捕捉分子相似性而设计的。两个化学结构相似的分子可能被编码成明显不同的SMILES字符串。这阻止了生成模型(如变分自编码器)学习平滑的分子嵌入。第二，基本的化学性质，如分子有效性，更容易在图形上表达，而不是线性的SMILES表示。我们假设直接在图上操作改良了有效化学结构的生成建模。

我们的主要贡献是一个新的分子图生成模型。虽然人们可以想象以一种标准的方式解决这个问题——逐节点生成图形(Li等人，2018)——但这种方法对于分子来说并不理想。这是因为==一个原子一个原子地创建分子会迫使模型生成化学上无效的中间体==，从而延迟验证直到生成一个完整的图。相反，我们建议生成两个阶段的分子图，利用有效的子图作为组件。整体的生成方法，作为一个连接树变分自编码器，首先生成一个树结构的对象(联合树)，它的作用是表示子图组件的脚手架及其大致的相对位置。组件是使用树分解从训练集自动提取有效的化学子结构，并用作构建块。在第二阶段，子图(树中的节点)被组装成一个分子图。

# 2 联合树变分自编码器

我们的方法通过引入合适的编码器和匹配的解码器，将变分自编码器扩展到分子图。与以往工作不同，我们将每个分子解释为从有效成分词汇表中选择的子图构建而成。当将分子编码为向量表示，以及将潜在向量解码回有效的分子图时，这些组件都被用作构建模块。这种观点的关键优势在于，解码器可以利用有效组分的集合以及它们如何相互作用来实现一个有效分子，而不是试图通过化学无效的中间体一个原子一个原子地构建分子。例如，一个芳香族键，除非整个芳香族环存在，否则其本身在化学上是无效的。

我们的成分词汇表(如环、键和单个原子)被选择得足够大，以至于给定的分子可以被重叠的成分或原子簇覆盖。簇的作用类似于图形模型中的cliques，因为它们的表达能力足以使分子可以被重叠的簇覆盖而不形成簇环。从这个意义上说，这些簇在分子图的一个(非最优的)三角形中充当cliques。我们将这些簇组成一个联合树，并将其用作分子的树状表示。因为我们团簇的选择是先验约束的，对于任意分子，我们不能保证有这样的团簇存在联合树。但是我们的聚类是基于训练集中的分子来构建的，以确保能够找到相应的连接树。根据经验，我们的簇覆盖了测试集中的大部分分子。

原始的分子图及其相关的连接树提供了分子的两种互补表示。因此，我们将分子编码为一个两部分的隐藏表示$z=[z_\tau,z_G]$，其中$z_\tau$编码树结构和树中的簇是什么，而没有完全捕获簇是如何相互连接的信息。$Z_G$对分子图进行编码，以捕获细粒度的连接性。这两个部分都是由树和图编码器$q(z_\tau|\tau)$和$q(z_G|G)$创建的。然后，隐藏表示在两个阶段被解码回一个分子图。首先使用基于$z_\tau$中的信息的树解码器$p(\tau|z_\tau)$重建连接树。其次利用图解码器$q(G|\tau,z_G)$预测连接树中簇之间的细粒度连接性，从而实现完全的分子图。联合树方法允许我们在生成过程中保持化学可行性。

## 2.1联合树

树分解通过将某些顶点收缩为单个节点把图G映射到一个连接树，G从而没有环路。形式上，对于图G，联合树$\Tau_G=(V,{\Large\varepsilon},X)$为一个连通标签树，节点集为$V=\{C_1,...,C_n\}$，边集为${\Large\varepsilon}$。每个节点或簇$C_i=(V_i,E_i)$为G的一个导出子图，满足以下约束：

1. 所有簇的并集为G，即${\large \cup}_i V_i=V$和${\large \cup}_i E_i=E$
2. 对任意的簇$C_i,C_j,C_k$，如果$C_k$在从$C_i$到$C_j$的路径上，$V_i\cap V_i \subseteq V_k$

将诱导子图视为聚类标签，联合树为词汇量为X的标签树。根据分子树分解，X只包含环和单边。因此词汇量是有限的(对于250K个分子的标准数据集$|X|$= 780)。

这里提出了为分子量身定制的树分解算法。我们的聚类词汇表X包括化学键和环等化学结构。给定一个图G，我们首先找到它所有的简单环，以及不属于任何环的边。如果两个简单的环有两个以上重叠的原子，它们就会合并在一起，因为它们构成了一种特定的结构，称为桥接化合物。这些圈或边中的每一条都被认为是一个簇。接下来，通过在所有相交的簇之间添加边来构造一个簇图。最后，我们选择其中一棵生成树作为G的联合树。由于环合并，连接树中的任意两个簇最多有两个原子是相同的，便于图解码阶段的高效推理。详细的操作步骤在补充部分有描述。

## 2.2图编码器

首先用一个图消息传递网络来编码G的潜在表示。每个顶点v都有一个特征向量$x_v$，表示原子类型、价态和其他属性。同样，每条边$(u, v)\in E$有一个特征向量$x_{uv}$表示其键类型，还有两个隐藏向量$v_{uv}$和$v_{vu}$表示信息从u传到u，反之亦然。由于图的环状结构，消息以环状的信念传播方式交换:
$$
\boldsymbol{\nu}_{u v}^{(t)}=\tau\left(\mathbf{W}_{1}^{g} \mathbf{x}_{u}+\mathbf{W}_{2}^{g} \mathbf{x}_{u v}+\mathbf{W}_{3}^{g} \sum_{w \in N(u) \backslash v} \boldsymbol{\nu}_{w u}^{(t-1)}\right)
$$
其中$v^{(t)}_{uv}$为第t轮计算得到的消息，初始化$v^{(t)}_{uv}=0$，T轮迭代后，聚合这些消息作为每个顶点的隐向量，捕获了它的局部图结构
$$
\mathbf{h}_{u}=\tau\left(\mathbf{U}_{1}^{g} \mathbf{x}_{u}+\sum_{v \in N(u)} \mathbf{U}_{2}^{g} \boldsymbol{\nu}_{v u}^{(T)}\right)
$$
最终的图表示为$\mathbf{h}_{G}=\sum_{i} \mathbf{h}_{i} /|V|$。用两个独立的仿射层从$h_G$计算变分后验近似的均值$\mu_G$和对数方差$\log\sigma_G $。$z_G$采样自高斯分布$N(\mu_G,\sigma_G)$。

## 2.3树编码器

同样用一个树消息传递网络对$T_G$进行编码。每个簇$C_i$由独热编码$x_i$表示其种类标签。每条边$(C_i, C_j)$与两个消息向量$m_{ij}$和$m_{ji}$相关联。我们选择任意一个叶节点作为根，在两个阶段传播消息。在第一个自底向上阶段，消息从叶节点发起，并迭代地向根传播。在自顶向下阶段，消息从根节点传播到所有叶节点。消息$m_{ij}$更新如下:
$$
\mathbf{m}_{i j}=\mathrm{GRU}\left(\mathbf{x}_{i},\left\{\mathbf{m}_{k i}\right\}_{k \in N(i) \backslash j}\right)
$$
其中GRU为用于树消息传递的门控循环单元：
$$
\begin{aligned}
\mathbf{s}_{i j} &=\sum_{k \in N(i) \backslash j} \mathbf{m}_{k i} \\
\mathbf{z}_{i j} &=\sigma\left(\mathbf{W}^{z} \mathbf{x}_{i}+\mathbf{U}^{z} \mathbf{s}_{i j}+\mathbf{b}^{z}\right) \\
\mathbf{r}_{k i} &=\sigma\left(\mathbf{W}^{r} \mathbf{x}_{i}+\mathbf{U}^{r} \mathbf{m}_{k i}+\mathbf{b}^{r}\right) \\
\tilde{\mathbf{m}}_{i j} &=\tanh \left(\mathbf{W} \mathbf{x}_{i}+\mathbf{U} \sum_{k \in N(i) \backslash j} \mathbf{r}_{k i} \odot \mathbf{m}_{k i}\right) \\
\mathbf{m}_{i j} &=\left(1-\mathbf{z}_{i j}\right) \odot \mathbf{s}_{i j}+\mathbf{z}_{i j} \odot \tilde{\mathbf{m}}_{i j}
\end{aligned}
$$
消息传递遵循以下调度：$m_{ij}$仅在其所有前驱$\left\{\mathbf{m}_{k i} \mid k \in N(i) \backslash j\right\}$都已计算时才计算。这种架构设计的动机是基于树的信念传播算法，因此与图形编码器不同。

消息传递后，我们通过聚合每个节点的内部消息，得到每个节点$h_i$的潜在表示:
$$
\mathbf{h}_{i}=\tau\left(\mathbf{W}^{o} \mathbf{x}_{i}+\sum_{k \in N(i)} \mathbf{U}^{o} \mathbf{m}_{k i}\right)
$$
最终的树表示是$h_{T_G}=T_{root}$，它编码了一个有根的树(T, root)。与图编码器不同，我们不使用节点平均池化，因为它混淆了树解码器首先生成哪个节点。$z_{\Tau_G}$的采样方式与图编码器类似。为简便起见，现在将$z_{\Tau_G}$缩写为$z_{\Tau}$。

这个树编码器在框架中扮演着两个角色。首先，它用于计算$z_{\Tau}$，这只需要自底向上的阶段，第二，在由$z_{\Tau}$解码出一个树$\hat{\Tau}$后，它被用来计算整个$\hat{\Tau}$的消息$\hat{m}_{ij}$，在图解码时提供每个节点的潜在上下文。这需要自上而下和自下而上两个阶段。

## 2.4树解码器

我们用树解码器从编码$z_{\Tau}$解码出联合树T。通过一次生成一个节点，该树以自顶向下的方式构建。树解码器从根遍历整个树，并按照深度优先的顺序生成节点。对于每个访问的节点，解码器首先做一个拓扑预测:该节点是否有子节点要生成。当创建一个新的子节点时，我们预测它的标签并递归这个过程。当一个节点没有更多的子节点生成时，解码器回溯。

在每个时间步中，一个节点从当前树中的其他节点接收信息，以便进行这些预测。增量构造树时，信息通过消息向量$h_{ij}$传播。形式上设$\tilde{\mathcal{E}}=\left\{\left(i_{1}, j_{1}\right), \cdots,\left(i_{m}, j_{m}\right)\right\}$是$T=(V,E)$的一次深度优先遍历经过的边，其中$m=2|\varepsilon |$因为每条边都在两个方向上遍历。模型在时刻t访问节点$i_t$。设$\tilde{\mathcal{E}}_t$是$\tilde{\mathcal{E}}$中的第一个t条边。消息$h_{i_t,j_t}$通过之前的消息被更新：
$$
\mathbf{h}_{i_{t}, j_{t}}=\operatorname{GRU}\left(\mathbf{x}_{i_{t}},\left\{\mathbf{h}_{k, i_{t}}\right\}_{\left(k, i_{t}\right) \in \tilde{\mathcal{E}}_{t}, k \neq j_{t}}\right)
$$
其中GRU是与树编码器相同的循环单元。

**拓扑预测**：当模型访问节点$i_t$时，它对其是否还有子节点进行二元预测。我们通过结合$z_{\Tau}$、节点特征$x_{i_t}$和消息$\mathbf{h}_{k, i_{t}}$来计算这个概率，它通过一个隐藏层网络，然后是一个sigmoid函数:
$$
p_{t}=\sigma\left(\mathbf{u}^{d} \cdot \tau\left(\mathbf{W}_{1}^{d} \mathbf{x}_{i_{t}}+\mathbf{W}_{2}^{d} \mathbf{z}_{\mathcal{T}}+\mathbf{W}_{3}^{d} \sum_{\left(k, i_{t}\right) \in \tilde{\mathcal{E}}_{t}} \mathbf{h}_{k, i_{t}}\right)\right.
$$
**标签预测**：当子节点j从其父节点i生成后，使用下式预测其节点标签
$$
\mathbf{q}_{j}=\operatorname{softmax}\left(\mathbf{U}^{l} \tau\left(\mathbf{W}_{1}^{l} \mathbf{z}_{\mathcal{T}}+\mathbf{W}_{2}^{l} \mathbf{h}_{i j}\right)\right)
$$
其中$q_j$为标签字典X上的分布，当j为根节点时，其父节点为一个虚拟节点并且$h_{ij}=0$

**学习**：树解码器的目标是最大化可能性$p(T|z_T)$。设$\hat{p}_t\in\{0,1\}$，$\hat{q}_j$为真实拓扑和标签值，解码器使以下交叉熵损失最小化
$$
\mathcal{L}_{c}(\mathcal{T})=\sum_{t} \mathcal{L}^{d}\left(p_{t}, \hat{p}_{t}\right)+\sum_{j} \mathcal{L}^{l}\left(\mathbf{q}_{j}, \hat{\mathbf{q}}_{j}\right)
$$
与序列生成类似，在训练过程中，执行teacher forcing:在每一步的拓扑和标签预测之后，将其替换为真值，以便在给定正确历史的情况下，模型做出预测。

**解码及可行性检查**：该树是在不使用任何外部指导训练的情况下，通过拓扑预测递归地构建的。为了保证采样树能够被实现为一个有效的分子，我们定义了集合$X_i$，包含有与节点i及其当前邻居在化学上兼容的簇标签。当从节点i生成一个子节点j时，通过屏蔽无效标签，以$X_i$上的归一化分布$q_j$下从$X_i$采样它的标签;

## 2.5图解码器

模型的最后一步是以预测联合树$\hat{T}=(\hat{V},{\Large\hat{\varepsilon})}$为基础重建分子图G。注意这一步不是确定的，因为可能有许多分子对应于相同的连接树。潜在的自由度与相邻簇$C_i$和$C_j$如何作为子图相互连接有关。我们的目标是将子图(树中的节点)组装成正确的分子图。设S(T)是连接树为T的图的集合，$\hat{T}=(\hat{V},{\Large\hat{\varepsilon})}$的解码图$\hat{G}$是一个结构化预测:
$$
\hat{G}=\arg \max _{G^{\prime} \in \mathcal{G}(\widehat{\mathcal{T}})} f^{a}\left(G^{\prime}\right)
$$
其中$f^a$是候选图上的评分函数。我们只考虑对簇与其邻居分解的函数进行评分。换句话说，评分函数中的每一项仅取决于簇$C_i$如何与树$\hat{T}$中相邻的簇$C_j$相连。出于效率的考虑，我们将按照树本身被解码的顺序，一次组装一个邻域的分子图。换句话说，我们首先根据根及其邻居的分数对它们的集合进行抽样。然后，我们继续组装邻居及其关联的簇(移除根组件设置的自由度)，等等。

每个社区实现的评分如下。设$G_i$为树中簇$C_i$与其邻居$C_j$的某一特定合并所产生的子图。我们通过首先推导一个向量表示$h_{G_i}$，然后使用$f^a_i(G_i)=h_{G_i}*z_G$将$G_i$作为候选子图进行评分。为此，让u, v指定为候选子图$G_i$中的原子;设$\alpha_v=i$如果$v \in C_i$以及$\alpha_v=j$如果$v \in C_j \setminus  C_i$。索引$\alpha_v$用于标记原子在连接树中的位置，并通过运行树编码算法沿着边(i,j)得到汇总了ii下子树的消息$\hat{m}_{i,j}$。与编码步骤类似，子图$G_i$中与原子和键相关的消息聚合到$h_{G_i}$中，但参数不同：
$$
\begin{array}{c}
\boldsymbol{\mu}_{u v}^{(t)} = \tau\left(\mathbf{W}_{1}^{a} \mathbf{x}_{u}+\mathbf{W}_{2}^{a} \mathbf{x}_{u v}+\mathbf{W}_{3}^{a} \widetilde{\boldsymbol{\mu}}_{u v}^{(t-1)}\right) \\
\tilde{\boldsymbol{\mu}}_{u v}^{(t-1)} = \left\{\begin{array}{ll}
\sum_{w \in N(u) \backslash v} \boldsymbol{\mu}_{w u}^{(t-1)} & \alpha_{u} = \alpha_{v} \\
\widehat{\mathbf{m}}_{\alpha_{u}, \alpha_{v}}+\sum_{w \in N(u) \backslash v} \boldsymbol{\mu}_{w u}^{(t-1)} & \alpha_{u} \neq \alpha_{v}
\end{array}\right.
\end{array}
$$
此处使用由在预测树$\widehat{\Tau}$上运行树编码器得到的树消息$\widehat{\mathbf{m}}_{\alpha_{u}, \alpha_{v}}$来增强模型，$\widehat{\mathbf{m}}_{\alpha_{u}, \alpha_{v}}$为边(u,v)提供了树相关位置上下文

**学习**：图解码器通过最大化在每个树节点预测真实图G的正确子图$G_i$的对数可能性来学习参数
$$
\mathcal{L}_{g}(G)=\sum_{i}\left[f^{a}\left(G_{i}\right)-\log \sum_{G_{i}^{\prime} \in \mathcal{G}_{i}} \exp \left(f^{a}\left(G_{i}^{\prime}\right)\right)\right]
$$
**复杂度**：通过树分解，任何两个簇最多共享两个原子，所以我们只需要合并最多两个原子或一个键。通过修剪化学无效的子图和合并同构图，在标准ZINC药物数据集上测试时，$|G_i|$平均约等于4。因此，在簇的数量上，JT-VAE的计算复杂度是线性的，可以很好地缩放到大型图。