# 监督学习：

提供一组样本{x~i~,y~i~},x~i~是一个特征向量，y~i~是输出，也是确定的值。目标是学习从x到y的映射关系f:x→y，要求f(x~i~)=y~i~

学习得到的映射f要求能够对任何未知的x^*^精确预测出f(x^*^)

# **分类：**

给定一组记录（训练集）

- 每个记录包含一个属性集，类class就是这些属性之一

为类特征找到一个模型作为其它属性值的函数

目标:以前未见的记录应该被尽可能准确地分配到一个类

用一个测试集来确定模型的准确性。通常将给定的数据集分为训练集和测试集，训练集用于建立模型，测试集用于验证模型。



## 分类技术

- 基于决策树的方法
- 基于规则的方法
- 基于内存或基于实例的方法
- 朴素贝叶斯分类器
- 支持向量机
- 神经网络
- 系综分类

## 决策树归纳算法:

- Hunt’s Algorithm (one of the earliest)
- CART
- ID3, C4.5
- SLIQ, SPRINT

### 亨特算法Hunt’s Algorithm的一般结构

设D~t~为到达节点t的训练记录集

一般过程:

- 如果D~t~包含的记录都属于同一类y~t~,那么t就是被标记为y~t~的一个叶子结点。
- 如果D~t~是空集,那么t就被作为默认类y~d~标记的叶节点。
- 如果Dt包含的结果有多个类别，就使用一个属性测试把数据分成更小的子集。整个子集递归执行这个过程。

### 拆分条件的表示方法

- 取决于属性类型（二元Binary，名词性词Nominal，有序型Ordinal，连续型Continuous）
- 取决于拆分方式（2路拆分2-way split，多路拆分multi-way split）

#### 基于名词性属性的拆分

- 多元分割:使用多个分区作为不同的值。
- 二元分割:将值分成两个子集。需要找到最优划分。

#### 基于有序属性的拆分

- 多元分割:使用和明显区别的值一样多的划分。
- 二元分割:将值分成两个子集。需要找到最优划分。

#### 基于连续属性的拆分

不同的处理方法:

离散形成一个有序的分类属性,区间[10,25],[25,50]

- 静态-在开始时离散一次
- 动态范围可以通过等间隔间隔间隔、等频率间隔(百分比)或群集来找到。

二元判定:(A < v)或(A≥v)

- 考虑所有可能的分割，找到最好的分割
- 可以更密集的计算

#### 如何决定最佳拆分

贪婪法:

纯度更高（homogeneous）的分布的结点被优先选取

需要结点的杂质值

例如C0: 5  C1: 5   	Non-homogeneous,高杂质度

C0: 9	C1: 1		Homogeneous,低杂质度

### 节点杂质测量

- 基尼系数
- 熵
- 误分类错误

#### 结点杂质值的测量方法---Gini Index（基尼指数）

给定节点t的基尼指数:

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804171531449.png" alt="image-20200804171531449" style="zoom:67%;" />

注：p(j | t)为类j在节点t处的相对频率

最大值(1 -1/n~c~)，当记录平均分布在所有类中，意味着最不感兴趣的信息（n~c~是类别总数）

最小值(0.0)，当所有记录都属于一个类时的表示最有趣的信息

![image-20200804171545748](D:\TyporaData\第二节、决策树与分类规则\image-20200804171545748.png)

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804173314670.png" alt="image-20200804173314670.png" style="zoom: 50%;" />



当节点p被分割成k个分区(子节点)时，分割的质量计算为<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804173527727.png" alt="image-20200804173527727" style="zoom: 50%;" />

n~i~=子节点i的记录数，n=节点p的记录数。

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804173711934.png" alt="image-20200804173711934" style="zoom:50%;" />

Gini(N1) = 1 –(5/7)^2^ –(2/7)^2^= 0.4082
Gini(N2) = 1 –(1/5)^2^ –(4/5)^2^= 0.3200
Gini(Children) = 7/12 * 0.4082 + 5/12 * 0.3200= 0.3715

**连续属性计算基尼指数的方法**

为了提高计算效率：对每个节点采取如下措施：

- 按值给属性排序
- 线性浏览这些值，每一次更新矩阵值并计算基尼指数
- 选择基尼指数最低的分割位置。

#### 结点杂质值的测量方法---熵Entropy

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804180404048.png" alt="image-20200804180404048" style="zoom:70%;" />

这里![p_{i}(t)](https://private.codecogs.com/gif.latex?p_%7Bi%7D%28t%29)是类i在结点t的频率，c是类的总数。

- 最大值是：此时记录的所有类别均匀分布，代表分类的最差情况。
- 最小值是0：此时所有记录均属于同一类别，代表分类的最好情况。
- 熵计算和基尼指数计算很类似

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200804180547332.png" alt="image-20200804180547332" style="zoom:67%;" />

##### 基于信息的分割

信息增益

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200808204051688.png" alt="image-20200808204051688" style="zoom: 67%;" />

父节点p被分成k个划分

测量由于分裂而达到的熵的减少。选择减少最多(获得最大收益)的分割

用于ID3和C4.5

劣势:

- 倾向于使用分割来产生大量的分区，每个分区都很小但很纯粹。

  

##### **增益率**

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200808204739160.png" alt="image-20200808204739160" style="zoom:67%;" />

- 通过分区熵(SplitINFO)调整信息增益。
- 更高熵的分区(大量的小分区)是不利的!
- 使用C4.5
- 旨在克服信息获取的不利因素

##### **误分类误差**

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200808205117581.png" alt="image-20200808205117581" style="zoom:67%;" />

- 度量节点所犯的错误分类错误。
- 最大值(1 -1/nc)，当记录平均分布在所有类中，意味着最不感兴趣的信息
- 最小值(0.0)：当所有记录都属于一个类时的，表示最有趣的信息

例：

<img src="D:\TyporaData\第二节、决策树与分类规则\image-20200808205240078.png" alt="image-20200808205240078" style="zoom:50%;" />

## 基于分类的决策树

优点:

构造简单

对未知记录的分类速度非常快

易于形成小的决策树

对于许多简单数据集，其准确性可与其他分类技术相媲美

## 基于规则的分类器

使用“if…then…”规则对记录进行分类

规则:(Condition)→y 

当：

- 条件是属性的连接
- 是类标签

时成立

LHS：规则的前提或条件

RHS：规则后件

分类规则示例:

(血型=温热)∧(下蛋=Yes)→鸟

### 规则覆盖范围和准确性

给定数据集D中的规则r:

r: A --> y

规则的覆盖范围:

满足规则前件的记录的部分

覆盖率(r) = |A| / |D|

规则的准确性:

同时满足规则的前件和后件的记录的一部分

准确性(r) = |A∩y| / |A|

### **基于规则的分类器的特征**

- 相互排斥的规则
  - 如果规则相互独立，则分类器包含互斥规则
  - 每条记录最多包含一条规则(<=1)，即没有两个规则是由同一记录触发的
- 详尽的规则
  - 如果分类器能够解释属性值的每一种可能的组合，那么它就是穷尽的覆盖
  - 每个记录至少包含一个规则(>=1)

### 从决策树到规则

从决策树生成的规则既互斥又详尽

规则集包含的信息与树一样多

### 有序的规则集

- 规则是根据其优先级排序的
  - 有序规则集称为决策列表
- 当一个测试记录被呈现给分类器时
  - 它被分配给它所触发的高级绑定规则的类标签
  - 如果没有规则触发，则将其分配给default class