# 感受

平时读论文也要注意写总结摘要，要把达到的改进结果多少百分比记录下来，以便在写论文时好写国内外研究情况。

# Title

An Effective Dual Self-Attention Residual Network for Seizure Prediction

一种有效的癫痫发作预测 双重注意力残差网络

# Abstract

癫痫发作预测是最具挑战性的数据分析任务之一，而且能极大地提高患者的生活质量。本文通过研究多通道脑电波信号特征的==时频相关性==，提出一种预测特定患者癫痫发作的通用方法：通过应用==短时傅立叶变换==到脑电波上,来把原始脑电波信号转换成代表时频特征的频谱图。首次使用==双重注意力残差网络==，将局部特征与全局特征相结合的**频谱注意模块**与挖掘信道映射之间相互依赖关系的**信道注意模块**相结合，来取得更好的预测性能。实验表明，不同的脑电波信号预测段长度是影响预测性能的重要因素。

# 1 Introduction

癫痫是脑过度活跃导致的脑神经紊乱。

不同患者有不同癫痫发作的频率

癫痫能通过脑电图信号分析和记录。脑电图是最有力的诊断工具

脑电图分为2种：1.头皮信号脑电图 2.颅内脑电图。

考虑到风险，当前主要研究头皮信号脑电图

大多数癫痫预测研究假设，癫痫脑电图信号有4种连续的大脑活动状态，包括发作前状态、发作状态、发作后状态、发作间状态。**Fig1**

癫痫预测研究就与识别发作前状态有关。癫痫预测研究的目的是区分发作间状态（近期不会发作）和发作前状态（即将发作）

Fig2是一般的癫痫预测系统流程包括数据获取、脑电图信号预处理、特征提取、分类和评估结果。一些研究从脑电图提取特征并用阈值区分发作间状态和发作前状态。Chu等人从脑电图数据集中6个频段的傅立叶系数，设置一个阈值进行分类，得到灵敏度为86.67%，虚警率0.367/h。Ibrahim等人提出了一种依赖于估计信号的概率密度函数(pdf)的统计时域方法。然后他们提出了脑电图通道选择和癫痫发作预测的概率阈值。然而，设置的阈值方法并没有考虑脑电信号的复杂性，也降低了癫痫发作预测的灵活性。传统机器学习算法也广泛应用到区分发作间状态和发作前状态，Rasekhi使用支持向量机和多层感知器。Vipin提出一种基于加权多尺度Renyi排列熵和FBSE的分类方法。Rishi等人提出了一种基于迭代滤波的癫痫脑电信号自动分类方法(IF)的脑电图信号，利用中频分解得到的本征模态函数和离散能量得到的包络函数提取特征。

随着深度学习在图像识别、文本分类和语音识别领域的发展，一些使用深度学习的癫痫发作预测方法也出现了

Khan等人提出将原始脑电图信号的小波变换作为卷积神经网络的输入。Ozcan等人[13]提出了一种多帧3DCNN模型，用于综合评估训练数据的时空依赖性。

事实上，大多数方法仍然不能提供可接受的性能。主要是因为：1. ==缺乏统一的标记数据==。单凭眼睛很难区分发作间期和发作前期，因为四个时期的界限很难界定。 2.==不同患者癫痫状态的的时间、特征和动态有很大差异==，因此，某些患者癫痫发作的典型特征可能不适用于其他患者

==目前没有针对每个患者实现高预测性能的通用方法，而是针对特定的患者进行专门的训练==。因此，大多数具有较高预测性能的研究都采用了针对患者的方法

在本文中，我们提出了一种==针对特定患者==的癫痫发作预测方法，通过开发基于深度学习的模型来提高癫痫发作预测的性能。该方法所使用的脑电图信号的==时频特性==对癫痫发作预测非常重要。已有研究将卷积神经网络应用于癫痫发作预测，证实了卷积神经网络是一种有效的对于脑电图分类的预测方法。但是由于脑电图信号的复杂和多样性以及卷积神经网络的简单结构，许多研究获得了较低性能。本次工作我们使用残差网络来提升性能，第一次使用了一个双重注意力残差网络RDANet来预测。==RDANet自适应地集成了脑电图信号的局部特征和全局特征==，这是通过频谱注意模块和信道注意模块实现；==增强了多通道脑电信号之间的相关性==。此外，我们使用==leave- one-out交叉验证==来评价预测结果。总之。对比已有的预测算法，数值实验证明了该算法的有效性

# 2 MATERIALS AND METHODS

## A. Dataset

CHB-MIT 头皮脑电图数据集包括包含22名儿童受试者的头皮脑电图(sEEG)数据，连续记录844小时，以256 Hz的采样频率从22个电极上采集脑电图信号。Litt等人[27]证实，复杂的癫痫放电在发作前7小时很常见，而类似癫痫发作的活跃发生在真正发作前2小时左右。累积的能量在发作前50分钟增加。本次研究中，定义==发作前状态是癫痫发作前30分钟的脑电图信号==，==定义发作间状态为癫痫发作4小时前和发作结束4小时后==。从临床的角度来看，最好是有一个足够长的干预，使有效的治疗干预或预防措施。在本研究中，==干预期设置为5分钟==，并==从训练数据中删除==。此外，考虑到癫痫发作发生的时间可能非常接近，我们有兴趣==预测第一次的癫痫==，==距离下一个大约不少于30分钟==。我们==只考虑一天发生不超过10次癫痫的病人==，因为对于平均每2小时发作一次的病人来说，执行这项任务并不是非常关键。

## B. Pre-Processing

由于癫痫是比较稀少的事件，==间期记录数比前期记录数要高==。***大多数机器学习算法假设不同种类的数据是均匀分布的。如果数据的数量不平衡，我们将获得偏向于较大数量类别的分类器。***为了解决数据平衡的问题，在训练期我们使用==重叠采样==来获得更多预测数据，如图Fig3.特别地，我们==定义发作前期信号的长度为**M**，发作间期信号的长度为**N**，计算两类数据长度比**K**==。设置==采样窗口S为5秒==。为了获得同样数量的2种数据，在训练期，==发作前期数据按照S*K的步长收集，间期数据按照S的步长收集==。脑电图信号被分割来获得前期和间期信号段，分别为a和b

时频域特征在脑电图数据分析中是很重要的，通常是通过在二维图中表示三个参数的谱图来研究的。小波变换和短时傅里叶变换STFT是将脑电图信号转为谱图的常用方法。==我们滑动5、15、30秒的窗口并用STFT将原始脑电图信号转为以时间和频率为轴的二维矩阵==如Fig3。CHB-MIT数据集中的大部分脑电图记录被60hz的电力线噪声污染，可以通过==排除频率范围为57-63 Hz和117-123 Hz的成分==有效地去除。同时==直流分量也被去除==。5秒脑电信号谱图及去噪谱图如Fig4所示。

## C. Model

我们提出的模型由残差网络和双重自我注意机制组成,==以Fig6上部的频谱注意模块为例，我们使用谱图作为网络的输入，通过残差网络提取潜在的时频特征。====然后，特征通过以下三个步骤输入到频谱注意模块来生成新的全局频谱特征。第一步是生成一个频谱注意矩阵来描述频谱图之间的空间关系。第二步，对注意矩阵和原始特征进行矩阵乘法。第三步，我们通过执行最后一步的结果矩阵和原始特征之间的元素求和来执行最终的全局频谱特征。====频道注意模块的过程与频谱注意模块的过程类似。我们将两个模块的特征进行融合，并将其添加到原始特征中，以更好地捕捉EEG信号的特征。==

### 1）Residual Network

卷积神经网络在计算机视觉、自然语言处理等方面得到了广泛的应用。科学研究表明，为了获得表达能力，更好地拟合潜在的映射关系，深化网络层数或拓宽网络结构是有效的。随着神经网络层数的增加，会出现梯度消失的问题，并且随机梯度下降算法的优化变得更加困难。最近He提出了一种残差网络来克服这些训练深度卷积网络时出现的困难，它由几个残差块组成。如Fig5，残差块通过快捷连接向网络添加身份映射，既没有添加额外的参数也没有额外计算，在一定程度上解决了模型退化问题。每个残差块由2个3*3卷积层，批归一化层，ReLu层组成。另外还添加有2个路径，即残差路径F(x)和单位映射x。这个案例我们使用4个残差块，相互连接

### 2) Dual Self-AttentionMechanism

注意机制起源于人类的视觉感知。当人类察觉一个物体时，他通常首先对整个图像进行扫描，然后将注意力集中到一个特定的部分，以获取更详细的信息，同时也忽略了其它无用信息。随着注意机制的进一步研究，注意力机制被谷歌机翻研究团队提出，收到了大量关注，因为它能学习到某个位置和其它位置的关系并捕捉语境依赖。我们首次在癫痫预测研究中==使用双重注意力机制来捕获脑电图信号的全局信息==，以下是其过程

a)频谱注意模块：如Fig6所示，有局部特征X∈R^C*H*W^，我们首先把它输入卷积层产生2个新的特征映射Y和Z，维度都是R^C*H*W^。然后将其reshape到R^C*N^，N=H*W。然后我们将Y的转置和Z进行矩阵乘法，获得权重矩阵S，然后通过softmax层

S~ij~代表第i个位置对第j个位置的影响，两个位置的特征表达越相似，它们之间的相关性就越大。同时通过将X输入进卷积层并reshape成R^C*N^，一个新的特征T∈R^C*H*W^表达将被生成。然后我们将T和S相乘，将结果reshape成R^C*H*W^。最终我们将其乘以一个缩放参数α，并对X执行逐元素求和运算，得到最终结果E∈R^C*H*W^。α初始成0，一点点地分配更多权重。最后的特征E是频谱加权特征与原始特征的和，具有全面的背景视角，并可根据频谱注意图选择性地收集全局信息。

b)频道注意模块：不同频道特征代表不同的脑电图语义。通道注意机制被用来挖掘通道映射间的相互依赖性。所以不同的语义表示是相互关联的。...

为了充分利用信道和频谱上下文信息，我们将这两个注意模块进行元素求和。与原始特征融合后，通过平均池化得到最终的特征图。

### 3) Training

为了获得近似于真实情况的结果，我们对每个病人应用了==留一交叉验证==方法。如果一个病人有n次癫痫以及t小时的发作间期被记录，整个发作间期记录被分成n个部分，每个部分有大约t/n小时，是随机与任一癫痫记录分组。这一轮做n次，每一次一对癫痫-间期对被保留进行测试，剩下的n-1对用来训练。==通常一些研究随机分出80%的数据作为训练集，20%为验证集来检测过拟合。然而这种方法适用于时间独立的数据，如图像分类。脑电图数据是时间相关的==，所以我们应该选择与训练时期不同的时间段作为样本来检测是否模型开始过拟合。在本研究中，我们从训练集中的发作前和发作间期记录中==选择25%的后期样本作为监测的验证集，75%用来训练集。==尽管训练期迭代次数会增加训练的精度，仍然会有过拟合的问题，可以通过==早停止==来解决。具体就是，当侦测到验证集的损失函数开始上升，我们停止训练并立即存储验证损失最低时的网络参数。

==DNANet网络的参数如Table2。模型输入是1\*22\*9\*114，22代表脑电图信号通道数，9\*114代表频谱图的维度，每个卷积层后边跟着一个批均一层，一个dropout层，一个ReLu激活函数层，我们首先通过把以上的特征映射输入一个卷积层并进行reshape获得一个64\*7\*28的数组。随后，使用4个残差块来提取脑电图的深层特征。融合全局特征的双重注意力层之后是具有sigmoid激活函数的全连接层我们采用交叉熵损失函数作为代价函数。batch大小是32。dropout率和学习率设置为0.5和0.0005。==我们的新模型==通过tensorflow 1.4.0的Keras 2.2.2实现==。

# 3 RESULTS

在本研究中，我们使用四个参数来评价所提出的模型的性能:灵敏度、特异性、准确性和AUC, AUC是一种常用的评价分类任务性能的指标，通过计算receiver operating 特征曲线 (ROC)下的面积。

CHB-MIT数据集中13个病例的CNN、ResNet和RDANet模型分别如Table III、IV和V所示。实验进行了两次，并给出了带有标准差的平均结果数值实验结果表明，模型的性能因患者的不同而不同。Table3所示，2、9、14号病人的结果低于其它病人。这是可以理解的因为2号病人只有3次癫痫，没有足够的发作前数据进行训练。以下解释原因

Table V显示了RDANet模型对CHB-MIT数据集中13例患者的评价结果。相比CNN和ResNet模型，RDANet模型对许多患者的评价结果有了改善

很少有研究探讨脑电图信号段长度对癫痫发作预测的影响。因此，我们探索了合适的脑电信号预测段长度，以获得最佳的预测性能。在本研究中，我们对所有癫痫发作预测长度为15秒和不同的模型进行重复训练30秒。图9是CNN的对比图，ResNet和RDANet模型分别对5秒、15秒和30秒的脑电图信号预测段进行评估。实验结果表明，该方法虽然具有较高的灵敏度

# 4 DISCUSSION

根据脑电信号的时间和空间分辨率，人们发展了多种统计技术来分析脑电信号。

# 5 CONCLUSION

在这项工作中，我们提出了一个预测癫痫发作的双注意力残差网络(RDANet)，它可以通过注意力机制将全局特征整合到局部特征中。具体来说，频谱注意模块和信道注意模块分别捕获了对频谱的全局依赖性和对信道的依赖性，提高了表达局部特征的能力。总的来说，我们提出的方法与其他最新方法相比是有竞争力的，而且由于没有针对患者的特征工程，所以是可推广的。而CHB-MIT数据集主要是儿童患者，我们的方法将在更多不同年龄组、不同临床条件的患者中进行综合测试，以确定整体表现。